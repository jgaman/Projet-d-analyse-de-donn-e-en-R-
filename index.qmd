---
title: "Projet Analyse de donn√©es en R, M2 IA School"
author: "Jean Luc GAMAN"

toc: true
code-fold: show
reader-mode: true
---

![](https://img.money.com/2022/02/News-2022-Graduate-Page-Gap.jpg)

# Data Analyse du data-set Wage Mid-Atlantic

Durant cette exploration nous t√¢cherons de r√©pondre aux questions suivantes :

1.  `Comment expliquer la diff√©rence de salaire entre indivus ?`

2.  `Est ce que le niveau d'√©tude a un impact sur les revenus de nos individus ?`

3.  `Peut-on pr√©dire quel sera le salaire d'un individu gr√¢ce √† son niveau d'√©tude ?`

## Installation des diff√©rentes Librairies

```{r, results='hide', message = FALSE}

library(tidyverse) # tout ce dont on a besoin pour modifier et analyser nos donn√©es
library(ISLR) #contient notre dataset Wage
library(flextable) # pour de belles pr√©sentations sous forme de tables
library(dlookr) # Analyse exploratoire de donn√©es, traitement des donn√©es manquantes et corr√©lation
library(ggstatsplot) # de belles visualisations statistiques et sommaire statistique de notre dataset
library(tidymodels) # Machine learning 
library(report) # ce package d√©crit automatiquement nos models et autres dataset
library(gtsummary) # de beau sommaire
library(DataExplorer) # rev√®le les donn√©es manquantes et permet de les remplacer
library(plotly) #interactive visualisation
library(performance) #performance et comparaison de mod√®les
library(sjPlot)
library(broom)   # pour tidy(), glance() & augment() fonctions
```

## Importons notre dataset

```{r}
df <- Wage
summary(df)
```

## D√©crivons notre dataset

```{r}
report(df)
```

## V√©rifions si notre dataset √† des donn√©es manquantes

```{r}
plot_intro(df)
```

ü©∫ Pas de donn√©es manquantes

```{r}
df |> 
  correlate() |> 
  plot()
```

## Visualisons nos donn√©es

### La race vs le niveau d'√©ducation

```{r, message=FALSE}
p  <- df |> 
  group_by(race) |> 
  plot_frq(education) |> 
    plot_grid()

```

üí°Par exemple, le sous-graphe C montre que la plupart des Afro-Am√©ricains de notre √©chantillon ont un niveau d'√©ducation √©lev√©.

### Type de Job

```{r}
plot_grpfrq(
  var.cnt = df$education,
  var.grp = df$jobclass
)
```

üí°Par exemple, elle montre clairement que la plupart des personnes ayant un faible niveau d'√©ducation travaillent dans des usines, tandis que les personnes ayant un niveau d'√©ducation plus √©lev√© travaillent dans le domaine de l'information.

### Essayons de d√©terminer qui gagne le plus, les travailleurs de l'industrie ou de l'information

```{r, message = FALSE, results = 'hide'}
df |> 
  group_by(jobclass) |> 
  plot_frq(wage, type = "histogram", show.mean = TRUE, normal.curve = TRUE) |> 
  plot_grid()
```

üí°Cette visualisation r√©v√®le que les travailleurs de l'industrie re√ßoivent **103 000 dollars en moyenne**, tandis que les informaticiens re√ßoivent **17 000 dollars de plus**.

## Cr√©ons un mod√®le de r√©gression lin√©aire

Notre mod√®le pr√©dit le salaire en fonction de l'√¢ge

```{r}

# Mod√®le de r√©gression lin√©aire simple qui pr√©dit les revenus en fonction de l'√¢ge

lm.fit <- lm(wage ~ age, data = df)
report(lm.fit)

# exemple de Pr√©diction du salaire en fonction de l'√¢ge
newdata <- data.frame(age = 55)
predict(lm.fit, newdata)

```

## Visualisons notre dataset avec la droite de r√©gression et notre mod√®le lin√©aire

```{r, message = FALSE}

# Cr√©er le graphique ggplot
p <- ggplot(df, aes(x = age, y = wage)) + 
  geom_point(aes(color = education)) + 
  geom_smooth(method = lm) +
  labs(title = "Relation entre l'√¢ge et le salaire", 
       x = "√Çge", y = "Salaire") +
  theme(plot.title = element_text(size = 18, face = "bold", hjust = 0.5)) + 
  theme_bw() +
  theme(legend.position = "bottom") +
  scale_color_discrete() +
  labs(title = "Relation entre l'√¢ge et le salaire") +
  
  # Ajouter une droite de r√©gression lin√©aire
  geom_smooth(method = "lm", se = FALSE, color = "black") 
  
# Convertir le graphique en un graphique Plotly interactif
ggplotly(p)
```

-   Par exemple, l'augmentation du salaire avec l'√¢ge est beaucoup plus importante lorsque l'on poss√®de au moins un dipl√¥me universitaire que si l'on n'a pas fait d'√©tudes. Ainsi, √† la fin de notre vie, nous aurons un salaire impressionnant de 150 000 dollars, alors que sans aucune formation, nous ne d√©passerons jamais la barre des 100 000 dollars.

-   Il semble donc que l'√©ducation soit importante, et la pente le montre clairement ! Cependant, bien que la pente du dipl√¥me d'√©tudes sup√©rieures soit beaucoup plus faible, ce qui pourrait sugg√©rer que l'√©ducation n'en vaut pas la peine, l'ordonn√©e √† l'origine raconte une autre histoire.

-   En effet, les personnes qui ont investi dans l'√©ducation d√®s le d√©part commencent leur vie avec le m√™me salaire que celui que les personnes qui ont fait des √©tudes sup√©rieures n'atteignent qu'√† la fin de leur vie.

-   Examinons attentivement ce mod√®le lin√©aire. Il indique que **la seule chose √† faire pour gagner beaucoup plus d'argent est de vieillir**. Mais pourquoi un groupe de personnes (`nos outliers`) gagne-t-il tellement plus que les autres ? et certaines personne aussi peu ? **Et un mod√®le unique est-il en mesure d'appr√©hender ces groupes ?**

-   Si l'on examine le niveau d'√©ducation de ces 3 000 personnes, on constate que la plupart des plus riches ont un dipl√¥me d'√©tudes sup√©rieures, tandis que la plupart des plus pauvres n'ont qu'un dipl√¥me d'√©tudes secondaires ou moins.

### cr√©ons un autre mod√®le lin√©aire afin de savoir si le niveau d'√©ducation √† un impacte sur le revenu

```{r}
m <- lm(wage ~ education, data = df)
plot_model(m, type = "pred")
report(m)
```

üí°Le trac√© de la pr√©diction m'indique imm√©diatement l'histoire. En effet, les personnes qui n'ont m√™me pas termin√© leurs √©tudes secondaires ont le salaire le plus bas par rapport √† tous les autres niveaux d'√©ducation. En outre, nous pouvons constater que l'augmentation du niveau d'√©ducation se traduit par une augmentation des salaires. **L'√©ducation est donc importante !**

## Analysons les Outliers du dataset

```{r}
df |> 
  select(wage) |> 
  plot_outlier()
```

```{r}
diagnose_outlier(df) |> flextable()
```

## Tableau crois√© de nos individus rang√©s par niveau d'√©ducation

```{r}
df |> 
  select(age, wage, education, jobclass, health_ins) |> 
  tbl_summary(by = education) 
```

Dans le premier cas, 144 personnes n'ont pas d'√©ducation ("1. \< HS Grad") et pas d'assurance maladie ("2. No").

## Splittons notre dataset en 10 groupes avec `group_by` et `nest`

Avant de pouvoir mod√©liser, nous devons diviser nos donn√©es en 10 groupes √† l'aide de la fonction `group_by()`, **puis verrouiller ces 10 groupes en 10 ensembles de donn√©es diff√©rents √† l'aide de la fonction** `nest()`**.**

```{r}
nested_data <- df |>  
  group_by(education, health_ins) |> 
  nest() 

nested_data
```

Dans un cadre de donn√©es imbriqu√©, chaque ligne est une m√©ta-observation o√π les variables cat√©gorielles "√©ducation et assurance maladie" d√©finissent nos 10 groupes, tandis que la colonne-liste de 10 ensembles de donn√©es peut √™tre consid√©r√©e comme 10 casiers contenant des observations individuelles appartenant uniquement √† une combinaison particuli√®re d'√©ducation et d'assurance maladie.

## It√©rons sur chacun des datasets cr√©√©s afin de cr√©er nos mod√®les

```{r, message=FALSE}

nested_models <- nested_data |> 
  mutate(models  = map(data, ~ lm(wage ~ age, data = .)), 
         coefs   = map(models, tidy, conf.int = TRUE),
         quality = map(models, glance),
         preds   = map(models, augment),
         performance = map(models, performance::check_model)) 

nested_models
```

-   **`mutate(data, models = map(data, ~ lm(wage ~ age, data = .)))`** : Cette ligne cr√©e une nouvelle colonne appel√©e "models" dans le dataframe "nested_data". Elle utilise la fonction map() pour appliquer la fonction lm() √† chaque √©l√©ment de la colonne "data", ajustant ainsi un mod√®le de r√©gression lin√©aire avec "wage" comme variable d√©pendante et "age" comme variable ind√©pendante.

-   **`mutate(models, coefs = map(models, tidy, conf.int = TRUE))`** : Cette ligne ajoute une nouvelle colonne appel√©e "coefs" au dataframe "nested_data". Elle utilise la fonction map() pour appliquer la fonction tidy() du package broom √† chaque √©l√©ment de la colonne "models". La fonction tidy() extrait les estimations des coefficients et les intervalles de confiance de chaque mod√®le de r√©gression lin√©aire.

-   **`mutate(models, quality = map(models, glance))`** : Cette ligne ajoute une nouvelle colonne appel√©e "quality" au dataframe "nested_data". Elle utilise la fonction map() pour appliquer la fonction glance() du package broom √† chaque √©l√©ment de la colonne "models". La fonction glance() fournit un r√©sum√© de l'ajustement du mod√®le, y compris diverses statistiques et m√©triques.

-   **`mutate(models, preds = map(models, augment))`** : Cette ligne ajoute une nouvelle colonne appel√©e "preds" au dataframe "nested_data". Elle utilise la fonction map() pour appliquer la fonction augment() du package broom √† chaque √©l√©ment de la colonne "models". La fonction augment() g√©n√®re des valeurs pr√©dites et d'autres informations sp√©cifiques au mod√®le.

-   **`mutate(models, performance = map(models, performance::check_model))`** : Cette ligne ajoute une nouvelle colonne appel√©e "performance" au dataframe "nested_data". Elle utilise la fonction map() pour appliquer la fonction check_model() du package performance √† chaque √©l√©ment de la colonne "models". La fonction check_model() √©value les performances du mod√®le et fournit des diagnostics pertinents.

-   Enfin, le code retourne le dataframe "nested_models", qui contient la colonne "data" d'origine, ainsi que les nouvelles colonnes "models", "coefs", "quality", "preds" et "performance".

-   Nous pouvons `map() library puur de tidyverse` sur chaque m√©ta-observation de notre cadre de donn√©es imbriqu√© et appliquer une r√©gression lin√©aire √† chacun des 10 data-sets qui sont stock√©s dans la colonne de liste que nous avons appel√©e "data".

-   De plus, plut√¥t que de laisser la liste des mod√®les comme des objets flottant librement , il est pr√©f√©rable de stocker tous nos mod√®les dans la colonne-list suivante, appelons cette colonne-list "mod√®les".

-   En outre, nous allons maintenant `map()` sur nos mod√®les afin d'extraire les coefficients avec les IC √† 95 %, les indicateurs de qualit√© du mod√®le et m√™me les pr√©dictions, et les stocker dans des colonnes distinctes.

## Maintenant que nous avons **une liste de 10 mod√®les nous pouvons, par exemple** :

Jeter un coup d'≈ìil au premier mod√®le ou √† ses coefficients et m√™me ces performance

```{r, message=FALSE, warning=FALSE}

report(nested_models$models[[1]])
```

```{r}
nested_models$models[[1]]
```

```{r}
nested_models$quality[[1]]
```

```{r, message = FALSE}

nested_models$performance[[1]]
```

nous pouvons v√©rifier toutes les hypoth√®ses du second mod√®le en une seule fois en utilisant la fonction `check_model()` du package `{performance}`,

nous pouvons regarder la qualit√© du mod√®le, disons, un mod√®le N¬∞4 ou

nous pouvons tracer les pr√©dictions d'un mod√®le N¬∞9 en utilisant la fonction plot_model() d'un autre package √©tonnant {sjPlot}.

## Utilisons la fonction `Unnest()`

### Imprimons les coefficients de chacun de nos mod√®les

```{r}
library(flextable) # for a good looking table
nested_models %>%
  unnest(coefs) %>% 
  select(-data, -models, -quality, -preds) %>% 
  mutate_if(is.numeric, ~ round(., 2)) %>% 
  regulartable() %>% 
  autofit()
```

### Imprimons les informations de qualit√© de chacun de tous nos mod√®les

```{r,  message=FALSE}
nested_models |>  
  unnest(quality) |>  
  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |> 
  arrange(adj.r.squared) |> 
  mutate_if(is.numeric, ~ round(., 2)) |>  
  regulartable() |>  
  autofit()
```

```{r}
unnested_preds <- 
  nested_models |> 
  unnest(preds)
```

```{r, message=FALSE}
ggplot(df, aes(x = age, y = wage, group = health_ins)) +
   geom_point(aes(color = health_ins), alpha = 0.2, shape = 1) +
   geom_smooth(method = "lm", size = 2) +
   facet_grid(. ~ education, scales = "free") +
   geom_line(data = unnested_preds, aes(y = .fitted, age, color = health_ins)) 
```

## Conclusion:

-   **L'augmentation du salaire avec l'√¢ge est beaucoup plus importante lorsque l'on poss√®de au moins un dipl√¥me universitaire** que si l'on n'a pas fait d'√©tudes. Ainsi, √† la fin de notre vie, nous aurons un salaire impressionnant de 150 000 dollars, alors que sans aucune formation, nous ne d√©passerons jamais la barre des 100 000 dollars.

-   **Il semble donc que l'√©ducation soit importante, et la pente le montre clairement !** Cependant, bien que la pente du dipl√¥me d'√©tudes sup√©rieures soit beaucoup plus faible, ce qui pourrait sugg√©rer que l'√©ducation n'en vaut pas la peine, l'ordonn√©e √† l'origine raconte une autre histoire.

-   **En effet, les personnes qui ont investi dans l'√©ducation d√®s le d√©part commencent leur vie avec le m√™me salaire que celui que les personnes qui ont fait des √©tudes sup√©rieures n'atteignent qu'√† la fin de leur vie.**

-   **Si l'on examine le niveau d'√©ducation de ces 3 000 personnes, on constate que la plupart des plus riches ont un dipl√¥me d'√©tudes sup√©rieures, tandis que la plupart des plus pauvres n'ont qu'un dipl√¥me d'√©tudes secondaires ou moins.**
