[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ã  Propos",
    "section": "",
    "text": "Description du dataset"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Durant cette exploration nous tÃ¢cherons de rÃ©pondre aux questions suivantes :\n\nComment expliquer la diffÃ©rence de salaire entre indivus ?\nEst ce que le niveau d'Ã©tude a un impact sur les revenus de nos individus ?\nPeut-on prÃ©dire quel sera le salaire d'un individu grÃ¢ce Ã  son niveau d'Ã©tude ?\n\n\n\n\n\nCode\nlibrary(tidyverse) # tout ce dont on a besoin pour modifier et analyser nos donnÃ©es\nlibrary(ISLR) #contient notre dataset Wage\nlibrary(flextable) # pour de belles prÃ©sentations sous forme de tables\nlibrary(dlookr) # Analyse exploratoire de donnÃ©es, traitement des donnÃ©es manquantes et corrÃ©lation\nlibrary(ggstatsplot) # de belles visualisations statistiques et sommaire statistique de notre dataset\nlibrary(tidymodels) # Machine learning \nlibrary(report) # ce package dÃ©crit automatiquement nos models et autres dataset\nlibrary(gtsummary) # de beau sommaire\nlibrary(DataExplorer) # revÃ¨le les donnÃ©es manquantes et permet de les remplacer\nlibrary(plotly) #interactive visualisation\nlibrary(performance) #performance et comparaison de modÃ¨les\nlibrary(sjPlot)\nlibrary(broom)   # pour tidy(), glance() & augment() fonctions\n\n\n\n\n\n\n\nCode\ndf &lt;- Wage\nsummary(df)\n\n\n      year           age                     maritl           race     \n Min.   :2003   Min.   :18.00   1. Never Married: 648   1. White:2480  \n 1st Qu.:2004   1st Qu.:33.75   2. Married      :2074   2. Black: 293  \n Median :2006   Median :42.00   3. Widowed      :  19   3. Asian: 190  \n Mean   :2006   Mean   :42.41   4. Divorced     : 204   4. Other:  37  \n 3rd Qu.:2008   3rd Qu.:51.00   5. Separated    :  55                  \n Max.   :2009   Max.   :80.00                                          \n                                                                       \n              education                     region               jobclass   \n 1. &lt; HS Grad      :268   2. Middle Atlantic   :3000   1. Industrial :1544  \n 2. HS Grad        :971   1. New England       :   0   2. Information:1456  \n 3. Some College   :650   3. East North Central:   0                        \n 4. College Grad   :685   4. West North Central:   0                        \n 5. Advanced Degree:426   5. South Atlantic    :   0                        \n                          6. East South Central:   0                        \n                          (Other)              :   0                        \n            health      health_ins      logwage           wage       \n 1. &lt;=Good     : 858   1. Yes:2083   Min.   :3.000   Min.   : 20.09  \n 2. &gt;=Very Good:2142   2. No : 917   1st Qu.:4.447   1st Qu.: 85.38  \n                                     Median :4.653   Median :104.92  \n                                     Mean   :4.654   Mean   :111.70  \n                                     3rd Qu.:4.857   3rd Qu.:128.68  \n                                     Max.   :5.763   Max.   :318.34  \n                                                                     \n\n\n\n\n\n\n\nCode\nreport(df)\n\n\nThe data contains 3000 observations of the following 11 variables:\n\n  - year: n = 3000, Mean = 2005.79, SD = 2.03, Median = 2006.00, MAD = 2.97,\nrange: [2003, 2009], Skewness = 0.14, Kurtosis = -1.27, 0% missing\n  - age: n = 3000, Mean = 42.41, SD = 11.54, Median = 42.00, MAD = 13.34, range:\n[18, 80], Skewness = 0.15, Kurtosis = -0.45, 0% missing\n  - maritl: 5 levels, namely 1. Never Married (n = 648, 21.60%), 2. Married (n =\n2074, 69.13%), 3. Widowed (n = 19, 0.63%), 4. Divorced (n = 204, 6.80%) and 5.\nSeparated (n = 55, 1.83%)\n  - race: 4 levels, namely 1. White (n = 2480, 82.67%), 2. Black (n = 293,\n9.77%), 3. Asian (n = 190, 6.33%) and 4. Other (n = 37, 1.23%)\n  - education: 5 levels, namely 1. &lt; HS Grad (n = 268, 8.93%), 2. HS Grad (n =\n971, 32.37%), 3. Some College (n = 650, 21.67%), 4. College Grad (n = 685,\n22.83%) and 5. Advanced Degree (n = 426, 14.20%)\n  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle Atlantic (n\n= 3000, 100.00%), 3. East North Central (n = 0, 0.00%), 4. West North Central\n(n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%), 6. East South Central (n = 0,\n0.00%), 7. West South Central (n = 0, 0.00%), 8. Mountain (n = 0, 0.00%) and 9.\nPacific (n = 0, 0.00%)\n  - jobclass: 2 levels, namely 1. Industrial (n = 1544, 51.47%) and 2.\nInformation (n = 1456, 48.53%)\n  - health: 2 levels, namely 1. &lt;=Good (n = 858, 28.60%) and 2. &gt;=Very Good (n =\n2142, 71.40%)\n  - health_ins: 2 levels, namely 1. Yes (n = 2083, 69.43%) and 2. No (n = 917,\n30.57%)\n  - logwage: n = 3000, Mean = 4.65, SD = 0.35, Median = 4.65, MAD = 0.31, range:\n[3, 5.76], Skewness = -0.12, Kurtosis = 1.73, 0% missing\n  - wage: n = 3000, Mean = 111.70, SD = 41.73, Median = 104.92, MAD = 32.91,\nrange: [20.09, 318.34], Skewness = 1.68, Kurtosis = 4.84, 0% missing\n\n\n\n\n\n\n\nCode\nplot_intro(df)\n\n\n\n\n\nðŸ©º Pas de donnÃ©es manquantes\n\n\nCode\ndf |&gt; \n  correlate() |&gt; \n  plot()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np  &lt;- df |&gt; \n  group_by(race) |&gt; \n  plot_frq(education) |&gt; \n    plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, race), education)): Not enough tags\nlabels in list. Using letters instead.\n\n\n\n\n\nðŸ’¡Par exemple, le sous-graphe C montre que la plupart des Afro-AmÃ©ricains de notre Ã©chantillon ont un niveau dâ€™Ã©ducation Ã©levÃ©.\n\n\n\n\n\nCode\nplot_grpfrq(\n  var.cnt = df$education,\n  var.grp = df$jobclass\n)\n\n\n\n\n\nðŸ’¡Par exemple, elle montre clairement que la plupart des personnes ayant un faible niveau dâ€™Ã©ducation travaillent dans des usines, tandis que les personnes ayant un niveau dâ€™Ã©ducation plus Ã©levÃ© travaillent dans le domaine de lâ€™information.\n\n\n\n\n\nCode\ndf |&gt; \n  group_by(jobclass) |&gt; \n  plot_frq(wage, type = \"histogram\", show.mean = TRUE, normal.curve = TRUE) |&gt; \n  plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, jobclass), wage, type = \"histogram\",\n: Not enough tags labels in list. Using letters instead.\n\n\n\n\n\nðŸ’¡Cette visualisation rÃ©vÃ¨le que les travailleurs de lâ€™industrie reÃ§oivent 103 000 dollars en moyenne, tandis que les informaticiens reÃ§oivent 17 000 dollars de plus.\n\n\n\n\nNotre modÃ¨le prÃ©dit le salaire en fonction de lâ€™Ã¢ge\n\n\nCode\n# ModÃ¨le de rÃ©gression linÃ©aire simple qui prÃ©dit les revenus en fonction de l'Ã¢ge\n\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# exemple de PrÃ©diction du salaire en fonction de l'Ã¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049 \n\n\n\n\n\n\n\nCode\n# CrÃ©er le graphique ggplot\np &lt;- ggplot(df, aes(x = age, y = wage)) + \n  geom_point(aes(color = education)) + \n  geom_smooth(method = lm) +\n  labs(title = \"Relation entre l'Ã¢ge et le salaire\", \n       x = \"Ã‚ge\", y = \"Salaire\") +\n  theme(plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5)) + \n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete() +\n  labs(title = \"Relation entre l'Ã¢ge et le salaire\") +\n  \n  # Ajouter une droite de rÃ©gression linÃ©aire\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") \n  \n# Convertir le graphique en un graphique Plotly interactif\nggplotly(p)\n\n\n\n\n\n\n\nPar exemple, lâ€™augmentation du salaire avec lâ€™Ã¢ge est beaucoup plus importante lorsque lâ€™on possÃ¨de au moins un diplÃ´me universitaire que si lâ€™on nâ€™a pas fait dâ€™Ã©tudes. Ainsi, Ã  la fin de notre vie, nous aurons un salaire impressionnant de 150 000 dollars, alors que sans aucune formation, nous ne dÃ©passerons jamais la barre des 100 000 dollars.\nIl semble donc que lâ€™Ã©ducation soit importante, et la pente le montre clairement ! Cependant, bien que la pente du diplÃ´me dâ€™Ã©tudes supÃ©rieures soit beaucoup plus faible, ce qui pourrait suggÃ©rer que lâ€™Ã©ducation nâ€™en vaut pas la peine, lâ€™ordonnÃ©e Ã  lâ€™origine raconte une autre histoire.\nEn effet, les personnes qui ont investi dans lâ€™Ã©ducation dÃ¨s le dÃ©part commencent leur vie avec le mÃªme salaire que celui que les personnes qui ont fait des Ã©tudes supÃ©rieures nâ€™atteignent quâ€™Ã  la fin de leur vie.\nExaminons attentivement ce modÃ¨le linÃ©aire. Il indique que la seule chose Ã  faire pour gagner beaucoup plus dâ€™argent est de vieillir. Mais pourquoi un groupe de personnes (nos outliers) gagne-t-il tellement plus que les autres ? et certaines personne aussi peu ? Et un modÃ¨le unique est-il en mesure dâ€™apprÃ©hender ces groupes ?\nSi lâ€™on examine le niveau dâ€™Ã©ducation de ces 3 000 personnes, on constate que la plupart des plus riches ont un diplÃ´me dâ€™Ã©tudes supÃ©rieures, tandis que la plupart des plus pauvres nâ€™ont quâ€™un diplÃ´me dâ€™Ã©tudes secondaires ou moins.\n\n\n\n\n\nCode\nm &lt;- lm(wage ~ education, data = df)\nplot_model(m, type = \"pred\")\n\n\n$education\n\n\n\n\n\nCode\nreport(m)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with education\n(formula: wage ~ education). The model explains a statistically significant and\nmoderate proportion of variance (R2 = 0.23, F(4, 2995) = 229.81, p &lt; .001, adj.\nR2 = 0.23). The model's intercept, corresponding to education = 1. &lt; HS Grad,\nis at 84.10 (95% CI [79.73, 88.48], t(2995) = 37.70, p &lt; .001). Within this\nmodel:\n\n  - The effect of education [2. HS Grad] is statistically significant and\npositive (beta = 11.68, 95% CI [6.74, 16.62], t(2995) = 4.63, p &lt; .001; Std.\nbeta = 0.28, 95% CI [0.16, 0.40])\n  - The effect of education [3. Some College] is statistically significant and\npositive (beta = 23.65, 95% CI [18.45, 28.85], t(2995) = 8.92, p &lt; .001; Std.\nbeta = 0.57, 95% CI [0.44, 0.69])\n  - The effect of education [4. College Grad] is statistically significant and\npositive (beta = 40.32, 95% CI [35.16, 45.48], t(2995) = 15.32, p &lt; .001; Std.\nbeta = 0.97, 95% CI [0.84, 1.09])\n  - The effect of education [5. Advanced Degree] is statistically significant and\npositive (beta = 66.81, 95% CI [61.23, 72.40], t(2995) = 23.46, p &lt; .001; Std.\nbeta = 1.60, 95% CI [1.47, 1.73])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nðŸ’¡Le tracÃ© de la prÃ©diction mâ€™indique immÃ©diatement lâ€™histoire. En effet, les personnes qui nâ€™ont mÃªme pas terminÃ© leurs Ã©tudes secondaires ont le salaire le plus bas par rapport Ã  tous les autres niveaux dâ€™Ã©ducation. En outre, nous pouvons constater que lâ€™augmentation du niveau dâ€™Ã©ducation se traduit par une augmentation des salaires. Lâ€™Ã©ducation est donc importante !\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(wage) |&gt; \n  plot_outlier()\n\n\n\n\n\n\n\nCode\ndiagnose_outlier(df) |&gt; flextable()\n\n\n\nvariablesoutliers_cntoutliers_ratiooutliers_meanwith_meanwithout_meanyear00.00000002,005.7910002,005.79100age40.133333380.00000042.41466742.36449logwage1264.20000004.8456264.6539054.64550wage1103.6666667254.185937111.703608106.28041\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(age, wage, education, jobclass, health_ins) |&gt; \n  tbl_summary(by = education) \n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1. &lt; HS Grad, N = 2681\n      2. HS Grad, N = 9711\n      3. Some College, N = 6501\n      4. College Grad, N = 6851\n      5. Advanced Degree, N = 4261\n    \n  \n  \n    age\n42 (33, 50)\n42 (33, 50)\n40 (32, 49)\n43 (34, 51)\n44 (38, 53)\n    wage\n81 (70, 97)\n94 (78, 110)\n105 (89, 121)\n119 (100, 143)\n142 (117, 171)\n    jobclass\n\n\n\n\n\n    Â Â Â Â 1. Industrial\n190 (71%)\n636 (65%)\n342 (53%)\n274 (40%)\n102 (24%)\n    Â Â Â Â 2. Information\n78 (29%)\n335 (35%)\n308 (47%)\n411 (60%)\n324 (76%)\n    health_ins\n\n\n\n\n\n    Â Â Â Â 1. Yes\n124 (46%)\n612 (63%)\n467 (72%)\n529 (77%)\n351 (82%)\n    Â Â Â Â 2. No\n144 (54%)\n359 (37%)\n183 (28%)\n156 (23%)\n75 (18%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nDans le premier cas, 144 personnes nâ€™ont pas dâ€™Ã©ducation (â€œ1. &lt; HS Gradâ€) et pas dâ€™assurance maladie (â€œ2. Noâ€).\n\n\n\nAvant de pouvoir modÃ©liser, nous devons diviser nos donnÃ©es en 10 groupes Ã  lâ€™aide de la fonction group_by(), puis verrouiller ces 10 groupes en 10 ensembles de donnÃ©es diffÃ©rents Ã  lâ€™aide de la fonction nest().\n\n\nCode\nnested_data &lt;- df |&gt;  \n  group_by(education, health_ins) |&gt; \n  nest() \n\nnested_data\n\n\n# A tibble: 10 Ã— 3\n# Groups:   education, health_ins [10]\n   education          health_ins data              \n   &lt;fct&gt;              &lt;fct&gt;      &lt;list&gt;            \n 1 1. &lt; HS Grad       2. No      &lt;tibble [144 Ã— 9]&gt;\n 2 4. College Grad    2. No      &lt;tibble [156 Ã— 9]&gt;\n 3 3. Some College    1. Yes     &lt;tibble [467 Ã— 9]&gt;\n 4 4. College Grad    1. Yes     &lt;tibble [529 Ã— 9]&gt;\n 5 2. HS Grad         1. Yes     &lt;tibble [612 Ã— 9]&gt;\n 6 2. HS Grad         2. No      &lt;tibble [359 Ã— 9]&gt;\n 7 5. Advanced Degree 2. No      &lt;tibble [75 Ã— 9]&gt; \n 8 5. Advanced Degree 1. Yes     &lt;tibble [351 Ã— 9]&gt;\n 9 3. Some College    2. No      &lt;tibble [183 Ã— 9]&gt;\n10 1. &lt; HS Grad       1. Yes     &lt;tibble [124 Ã— 9]&gt;\n\n\nDans un cadre de donnÃ©es imbriquÃ©, chaque ligne est une mÃ©ta-observation oÃ¹ les variables catÃ©gorielles â€œÃ©ducation et assurance maladieâ€ dÃ©finissent nos 10 groupes, tandis que la colonne-liste de 10 ensembles de donnÃ©es peut Ãªtre considÃ©rÃ©e comme 10 casiers contenant des observations individuelles appartenant uniquement Ã  une combinaison particuliÃ¨re dâ€™Ã©ducation et dâ€™assurance maladie.\n\n\n\n\n\nCode\nnested_models &lt;- nested_data |&gt; \n  mutate(models  = map(data, ~ lm(wage ~ age, data = .)), \n         coefs   = map(models, tidy, conf.int = TRUE),\n         quality = map(models, glance),\n         preds   = map(models, augment),\n         performance = map(models, performance::check_model)) \n\nnested_models\n\n\n# A tibble: 10 Ã— 8\n# Groups:   education, health_ins [10]\n   education   health_ins data     models coefs    quality  preds    performance\n   &lt;fct&gt;       &lt;fct&gt;      &lt;list&gt;   &lt;list&gt; &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;     \n 1 1. &lt; HS Grâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 2 4. Collegeâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 3 3. Some Coâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 4 4. Collegeâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 5 2. HS Grad  1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 6 2. HS Grad  2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 7 5. Advanceâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 8 5. Advanceâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 9 3. Some Coâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n10 1. &lt; HS Grâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n\n\n\nmutate(data, models = map(data, ~ lm(wage ~ age, data = .))) : Cette ligne crÃ©e une nouvelle colonne appelÃ©e â€œmodelsâ€ dans le dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction lm() Ã  chaque Ã©lÃ©ment de la colonne â€œdataâ€, ajustant ainsi un modÃ¨le de rÃ©gression linÃ©aire avec â€œwageâ€ comme variable dÃ©pendante et â€œageâ€ comme variable indÃ©pendante.\nmutate(models, coefs = map(models, tidy, conf.int = TRUE)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œcoefsâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction tidy() du package broom Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction tidy() extrait les estimations des coefficients et les intervalles de confiance de chaque modÃ¨le de rÃ©gression linÃ©aire.\nmutate(models, quality = map(models, glance)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œqualityâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction glance() du package broom Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction glance() fournit un rÃ©sumÃ© de lâ€™ajustement du modÃ¨le, y compris diverses statistiques et mÃ©triques.\nmutate(models, preds = map(models, augment)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œpredsâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction augment() du package broom Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction augment() gÃ©nÃ¨re des valeurs prÃ©dites et dâ€™autres informations spÃ©cifiques au modÃ¨le.\nmutate(models, performance = map(models, performance::check_model)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œperformanceâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction check_model() du package performance Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction check_model() Ã©value les performances du modÃ¨le et fournit des diagnostics pertinents.\nEnfin, le code retourne le dataframe â€œnested_modelsâ€, qui contient la colonne â€œdataâ€ dâ€™origine, ainsi que les nouvelles colonnes â€œmodelsâ€, â€œcoefsâ€, â€œqualityâ€, â€œpredsâ€ et â€œperformanceâ€.\nNous pouvons map() library puur de tidyverse sur chaque mÃ©ta-observation de notre cadre de donnÃ©es imbriquÃ© et appliquer une rÃ©gression linÃ©aire Ã  chacun des 10 data-sets qui sont stockÃ©s dans la colonne de liste que nous avons appelÃ©e â€œdataâ€.\nDe plus, plutÃ´t que de laisser la liste des modÃ¨les comme des objets flottant librement , il est prÃ©fÃ©rable de stocker tous nos modÃ¨les dans la colonne-list suivante, appelons cette colonne-list â€œmodÃ¨lesâ€.\nEn outre, nous allons maintenant map() sur nos modÃ¨les afin dâ€™extraire les coefficients avec les IC Ã  95 %, les indicateurs de qualitÃ© du modÃ¨le et mÃªme les prÃ©dictions, et les stocker dans des colonnes distinctes.\n\n\n\n\nJeter un coup dâ€™Å“il au premier modÃ¨le ou Ã  ses coefficients et mÃªme ces performance\n\n\nCode\nreport(nested_models$models[[1]])\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically not significant and\nvery weak proportion of variance (R2 = 0.01, F(1, 142) = 1.45, p = 0.230, adj.\nR2 = 3.14e-03). The model's intercept, corresponding to age = 0, is at 69.80\n(95% CI [59.21, 80.39], t(142) = 13.03, p &lt; .001). Within this model:\n\n  - The effect of age is statistically non-significant and positive (beta = 0.16,\n95% CI [-0.10, 0.42], t(142) = 1.20, p = 0.230; Std. beta = 0.10, 95% CI\n[-0.06, 0.27])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nCode\nnested_models$models[[1]]\n\n\n\nCall:\nlm(formula = wage ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    69.8032       0.1572  \n\n\n\n\nCode\nnested_models$quality[[1]]\n\n\n# A tibble: 1 Ã— 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0101       0.00314  20.1      1.45   0.230     1  -636. 1277. 1286.\n# â„¹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nnested_models$performance[[1]]\n\n\n\n\n\nnous pouvons vÃ©rifier toutes les hypothÃ¨ses du second modÃ¨le en une seule fois en utilisant la fonction check_model() du package {performance},\nnous pouvons regarder la qualitÃ© du modÃ¨le, disons, un modÃ¨le NÂ°4 ou\nnous pouvons tracer les prÃ©dictions dâ€™un modÃ¨le NÂ°9 en utilisant la fonction plot_model() dâ€™un autre package Ã©tonnant {sjPlot}.\n\n\n\n\n\n\n\nCode\nlibrary(flextable) # for a good looking table\nnested_models %&gt;%\n  unnest(coefs) %&gt;% \n  select(-data, -models, -quality, -preds) %&gt;% \n  mutate_if(is.numeric, ~ round(., 2)) %&gt;% \n  regulartable() %&gt;% \n  autofit()\n\n\n`mutate_if()` ignored the following grouping variables:\nâ€¢ Columns `education`, `health_ins`\n\n\n\neducationhealth_instermestimatestd.errorstatisticp.valueconf.lowconf.highperformance1. &lt; HS Grad2. No(Intercept)69.805.3613.030.0059.2180.39[[check_model]]1. &lt; HS Grad2. Noage0.160.131.200.23-0.100.42[[check_model]]4. College Grad2. No(Intercept)91.8410.488.760.0071.13112.55[[check_model]]4. College Grad2. Noage0.270.241.150.25-0.200.74[[check_model]]3. Some College1. Yes(Intercept)86.144.9317.480.0076.4695.83[[check_model]]3. Some College1. Yesage0.630.115.570.000.410.85[[check_model]]4. College Grad1. Yes(Intercept)109.067.3614.830.0094.61123.51[[check_model]]4. College Grad1. Yesage0.500.173.020.000.180.83[[check_model]]2. HS Grad1. Yes(Intercept)90.594.4720.250.0081.8099.37[[check_model]]2. HS Grad1. Yesage0.270.102.740.010.080.46[[check_model]]2. HS Grad2. No(Intercept)66.754.4914.860.0057.9275.58[[check_model]]2. HS Grad2. Noage0.450.114.120.000.240.67[[check_model]]5. Advanced Degree2. No(Intercept)97.0625.913.750.0045.43148.70[[check_model]]5. Advanced Degree2. Noage0.730.531.380.17-0.331.80[[check_model]]5. Advanced Degree1. Yes(Intercept)131.1513.0210.080.00105.55156.75[[check_model]]5. Advanced Degree1. Yesage0.540.291.880.06-0.031.10[[check_model]]3. Some College2. No(Intercept)44.848.745.130.0027.5962.08[[check_model]]3. Some College2. Noage1.340.226.040.000.901.77[[check_model]]1. &lt; HS Grad1. Yes(Intercept)78.746.9111.390.0065.0692.43[[check_model]]1. &lt; HS Grad1. Yesage0.330.152.220.030.040.62[[check_model]]\n\n\n\n\n\n\n\nCode\nnested_models |&gt;  \n  unnest(quality) |&gt;  \n  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |&gt; \n  arrange(adj.r.squared) |&gt; \n  mutate_if(is.numeric, ~ round(., 2)) |&gt;  \n  regulartable() |&gt;  \n  autofit()\n\n\n\neducationhealth_insr.squaredadj.r.squaredsigmastatisticp.valuelogLikAICBICnobsperformance4. College Grad2. No0.010.0035.771.310.25-778.391,562.771,571.92156[[check_model]]1. &lt; HS Grad2. No0.010.0020.141.450.23-635.691,277.381,286.29144[[check_model]]5. Advanced Degree1. Yes0.010.0153.333.530.06-1,892.833,791.663,803.24351[[check_model]]2. HS Grad1. Yes0.010.0127.567.510.01-2,897.115,800.225,813.47612[[check_model]]5. Advanced Degree2. No0.030.0151.511.890.17-401.04808.08815.0475[[check_model]]4. College Grad1. Yes0.020.0240.349.120.00-2,705.505,417.005,429.81529[[check_model]]1. &lt; HS Grad1. Yes0.040.0318.904.920.03-539.421,084.831,093.30124[[check_model]]2. HS Grad2. No0.050.0425.7817.000.00-1,674.983,355.963,367.61359[[check_model]]3. Some College1. Yes0.060.0626.9931.020.00-2,200.624,407.244,419.68467[[check_model]]3. Some College2. No0.170.1636.0436.510.00-914.661,835.311,844.94183[[check_model]]\n\n\n\n\nCode\nunnested_preds &lt;- \n  nested_models |&gt; \n  unnest(preds)\n\n\n\n\nCode\nggplot(df, aes(x = age, y = wage, group = health_ins)) +\n   geom_point(aes(color = health_ins), alpha = 0.2, shape = 1) +\n   geom_smooth(method = \"lm\", size = 2) +\n   facet_grid(. ~ education, scales = \"free\") +\n   geom_line(data = unnested_preds, aes(y = .fitted, age, color = health_ins)) \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead."
  },
  {
    "objectID": "about.html#format",
    "href": "about.html#format",
    "title": "Ã  Propos",
    "section": "Format",
    "text": "Format\nA data frame with 3000 observations on the following 11 variables.\n\nyear\n\nYear that wage information was recorded\n\nage\n\nAge of worker\n\nmaritl\n\nA factor with levels 1. Never Married 2. Married 3. Widowed 4. Divorced and 5. Separated indicating marital status\n\nrace\n\nA factor with levels 1. White 2. Black 3. Asian and 4. Other indicating race\n\neducation\n\nA factor with levels 1. &lt; HS Grad 2. HS Grad 3. Some College 4. College Grad and 5. Advanced Degree indicating education level\n\nregion\n\nRegion of the country (mid-atlantic only)\n\njobclass\n\nA factor with levels 1. Industrial and 2. Information indicating type of job\n\nhealth\n\nA factor with levels 1. &lt;=Good and 2. &gt;=Very Good indicating health level of worker\n\nhealth_ins\n\nA factor with levels 1. Yes and 2. No indicating whether worker has health insurance\n\nlogwage\n\nLog of workers wage\n\nwage\n\nWorkers raw wage"
  },
  {
    "objectID": "index.html#sommaire-de-notre-dataset",
    "href": "index.html#sommaire-de-notre-dataset",
    "title": "Projet Analyse de donnÃ©es en R",
    "section": "Sommaire de notre dataset",
    "text": "Sommaire de notre dataset\n\ndf |> \n  select(age, wage, education, jobclass, race) |> \n  tbl_summary(by = education) \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1. < HS Grad, N = 2681\n      2. HS Grad, N = 9711\n      3. Some College, N = 6501\n      4. College Grad, N = 6851\n      5. Advanced Degree, N = 4261\n    \n  \n  \n    age\n42 (33, 50)\n42 (33, 50)\n40 (32, 49)\n43 (34, 51)\n44 (38, 53)\n    wage\n81 (70, 97)\n94 (78, 110)\n105 (89, 121)\n119 (100, 143)\n142 (117, 171)\n    jobclass\n\n\n\n\n\n    Â Â Â Â 1. Industrial\n190 (71%)\n636 (65%)\n342 (53%)\n274 (40%)\n102 (24%)\n    Â Â Â Â 2. Information\n78 (29%)\n335 (35%)\n308 (47%)\n411 (60%)\n324 (76%)\n    race\n\n\n\n\n\n    Â Â Â Â 1. White\n211 (79%)\n822 (85%)\n532 (82%)\n576 (84%)\n339 (80%)\n    Â Â Â Â 2. Black\n31 (12%)\n105 (11%)\n92 (14%)\n40 (5.8%)\n25 (5.9%)\n    Â Â Â Â 3. Asian\n15 (5.6%)\n31 (3.2%)\n18 (2.8%)\n66 (9.6%)\n60 (14%)\n    Â Â Â Â 4. Other\n11 (4.1%)\n13 (1.3%)\n8 (1.2%)\n3 (0.4%)\n2 (0.5%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)"
  },
  {
    "objectID": "index.html#decrivons-notre-dataset",
    "href": "index.html#decrivons-notre-dataset",
    "title": "Projet Analyse de donnÃ©es en R",
    "section": "Decrivons notre dataset",
    "text": "Decrivons notre dataset\n\ndf |> \n  select(age, wage, education, jobclass, race) |> \n  group_by(education) |>\n  report() |> \n  summary()\n\nThe data contains 3000 observations, grouped by education, of the following 5\nvariables:\n\n- 1. < HS Grad (n = 268):\n  - age: Mean = 41.79, SD = 12.61, range: [18, 75]\n  - wage: Mean = 84.10, SD = 21.58, range: [20.93, 152.22]\n  - jobclass: 2 levels, namely 1. Industrial (n = 190) and 2. Information (n =\n78)\n  - race: 4 levels, namely 1. White (n = 211), 2. Black (n = 31), 3. Asian (n =\n15) and 4. Other (n = 11)\n\n- 2. HS Grad (n = 971):\n  - age: Mean = 42.22, SD = 12.02, range: [18, 80]\n  - wage: Mean = 95.78, SD = 28.57, range: [23.27, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 636) and 2. Information (n =\n335)\n  - race: 4 levels, namely 1. White (n = 822), 2. Black (n = 105), 3. Asian (n =\n31) and 4. Other (n = 13)\n\n- 3. Some College (n = 650):\n  - age: Mean = 40.89, SD = 11.52, range: [18, 80]\n  - wage: Mean = 107.76, SD = 32.47, range: [20.09, 314.33]\n  - jobclass: 2 levels, namely 1. Industrial (n = 342) and 2. Information (n =\n308)\n  - race: 4 levels, namely 1. White (n = 532), 2. Black (n = 92), 3. Asian (n =\n18) and 4. Other (n = 8)\n\n- 4. College Grad (n = 685):\n  - age: Mean = 42.77, SD = 10.90, range: [22, 76]\n  - wage: Mean = 124.43, SD = 41.19, range: [32.37, 281.75]\n  - jobclass: 2 levels, namely 1. Industrial (n = 274) and 2. Information (n =\n411)\n  - race: 4 levels, namely 1. White (n = 576), 2. Black (n = 40), 3. Asian (n =\n66) and 4. Other (n = 3)\n\n- 5. Advanced Degree (n = 426):\n  - age: Mean = 45.01, SD = 10.26, range: [25, 76]\n  - wage: Mean = 150.92, SD = 53.90, range: [38.61, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 102) and 2. Information (n =\n324)\n  - race: 4 levels, namely 1. White (n = 339), 2. Black (n = 25), 3. Asian (n =\n60) and 4. Other (n = 2)"
  },
  {
    "objectID": "index.html#tableau-croisÃ©-de-nos-individus-rangÃ©s-par-niveau-dÃ©ducation",
    "href": "index.html#tableau-croisÃ©-de-nos-individus-rangÃ©s-par-niveau-dÃ©ducation",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\ndf |&gt; \n  select(age, wage, education, jobclass, health_ins) |&gt; \n  tbl_summary(by = education) \n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1. &lt; HS Grad, N = 2681\n      2. HS Grad, N = 9711\n      3. Some College, N = 6501\n      4. College Grad, N = 6851\n      5. Advanced Degree, N = 4261\n    \n  \n  \n    age\n42 (33, 50)\n42 (33, 50)\n40 (32, 49)\n43 (34, 51)\n44 (38, 53)\n    wage\n81 (70, 97)\n94 (78, 110)\n105 (89, 121)\n119 (100, 143)\n142 (117, 171)\n    jobclass\n\n\n\n\n\n    Â Â Â Â 1. Industrial\n190 (71%)\n636 (65%)\n342 (53%)\n274 (40%)\n102 (24%)\n    Â Â Â Â 2. Information\n78 (29%)\n335 (35%)\n308 (47%)\n411 (60%)\n324 (76%)\n    health_ins\n\n\n\n\n\n    Â Â Â Â 1. Yes\n124 (46%)\n612 (63%)\n467 (72%)\n529 (77%)\n351 (82%)\n    Â Â Â Â 2. No\n144 (54%)\n359 (37%)\n183 (28%)\n156 (23%)\n75 (18%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nDans le premier cas, 144 personnes nâ€™ont pas dâ€™Ã©ducation (â€œ1. &lt; HS Gradâ€) et pas dâ€™assurance maladie (â€œ2. Noâ€)."
  },
  {
    "objectID": "index.html#dÃ©crivons-ce-tableau-croisÃ©",
    "href": "index.html#dÃ©crivons-ce-tableau-croisÃ©",
    "title": "Projet Analyse de donnÃ©es en R",
    "section": "DÃ©crivons ce Tableau croisÃ©",
    "text": "DÃ©crivons ce Tableau croisÃ©\n\ndf |> \n  select(age, wage, education, jobclass, race) |> \n  group_by(education) |>\n  report() |> \n  summary()\n\nThe data contains 3000 observations, grouped by education, of the following 5\nvariables:\n\n- 1. < HS Grad (n = 268):\n  - age: Mean = 41.79, SD = 12.61, range: [18, 75]\n  - wage: Mean = 84.10, SD = 21.58, range: [20.93, 152.22]\n  - jobclass: 2 levels, namely 1. Industrial (n = 190) and 2. Information (n =\n78)\n  - race: 4 levels, namely 1. White (n = 211), 2. Black (n = 31), 3. Asian (n =\n15) and 4. Other (n = 11)\n\n- 2. HS Grad (n = 971):\n  - age: Mean = 42.22, SD = 12.02, range: [18, 80]\n  - wage: Mean = 95.78, SD = 28.57, range: [23.27, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 636) and 2. Information (n =\n335)\n  - race: 4 levels, namely 1. White (n = 822), 2. Black (n = 105), 3. Asian (n =\n31) and 4. Other (n = 13)\n\n- 3. Some College (n = 650):\n  - age: Mean = 40.89, SD = 11.52, range: [18, 80]\n  - wage: Mean = 107.76, SD = 32.47, range: [20.09, 314.33]\n  - jobclass: 2 levels, namely 1. Industrial (n = 342) and 2. Information (n =\n308)\n  - race: 4 levels, namely 1. White (n = 532), 2. Black (n = 92), 3. Asian (n =\n18) and 4. Other (n = 8)\n\n- 4. College Grad (n = 685):\n  - age: Mean = 42.77, SD = 10.90, range: [22, 76]\n  - wage: Mean = 124.43, SD = 41.19, range: [32.37, 281.75]\n  - jobclass: 2 levels, namely 1. Industrial (n = 274) and 2. Information (n =\n411)\n  - race: 4 levels, namely 1. White (n = 576), 2. Black (n = 40), 3. Asian (n =\n66) and 4. Other (n = 3)\n\n- 5. Advanced Degree (n = 426):\n  - age: Mean = 45.01, SD = 10.26, range: [25, 76]\n  - wage: Mean = 150.92, SD = 53.90, range: [38.61, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 102) and 2. Information (n =\n324)\n  - race: 4 levels, namely 1. White (n = 339), 2. Black (n = 25), 3. Asian (n =\n60) and 4. Other (n = 2)"
  },
  {
    "objectID": "index.html#installation-des-diffÃ©rentes-librairies",
    "href": "index.html#installation-des-diffÃ©rentes-librairies",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\nlibrary(tidyverse) # tout ce dont on a besoin pour modifier et analyser nos donnÃ©es\nlibrary(ISLR) #contient notre dataset Wage\nlibrary(flextable) # pour de belles prÃ©sentations sous forme de tables\nlibrary(dlookr) # Analyse exploratoire de donnÃ©es, traitement des donnÃ©es manquantes et corrÃ©lation\nlibrary(ggstatsplot) # de belles visualisations statistiques et sommaire statistique de notre dataset\nlibrary(tidymodels) # Machine learning \nlibrary(report) # ce package dÃ©crit automatiquement nos models et autres dataset\nlibrary(gtsummary) # de beau sommaire\nlibrary(DataExplorer) # revÃ¨le les donnÃ©es manquantes et permet de les remplacer\nlibrary(plotly) #interactive visualisation\nlibrary(performance) #performance et comparaison de modÃ¨les\nlibrary(sjPlot)\nlibrary(broom)   # pour tidy(), glance() & augment() fonctions"
  },
  {
    "objectID": "index.html#importons-notre-dataset",
    "href": "index.html#importons-notre-dataset",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\ndf &lt;- Wage\nsummary(df)\n\n\n      year           age                     maritl           race     \n Min.   :2003   Min.   :18.00   1. Never Married: 648   1. White:2480  \n 1st Qu.:2004   1st Qu.:33.75   2. Married      :2074   2. Black: 293  \n Median :2006   Median :42.00   3. Widowed      :  19   3. Asian: 190  \n Mean   :2006   Mean   :42.41   4. Divorced     : 204   4. Other:  37  \n 3rd Qu.:2008   3rd Qu.:51.00   5. Separated    :  55                  \n Max.   :2009   Max.   :80.00                                          \n                                                                       \n              education                     region               jobclass   \n 1. &lt; HS Grad      :268   2. Middle Atlantic   :3000   1. Industrial :1544  \n 2. HS Grad        :971   1. New England       :   0   2. Information:1456  \n 3. Some College   :650   3. East North Central:   0                        \n 4. College Grad   :685   4. West North Central:   0                        \n 5. Advanced Degree:426   5. South Atlantic    :   0                        \n                          6. East South Central:   0                        \n                          (Other)              :   0                        \n            health      health_ins      logwage           wage       \n 1. &lt;=Good     : 858   1. Yes:2083   Min.   :3.000   Min.   : 20.09  \n 2. &gt;=Very Good:2142   2. No : 917   1st Qu.:4.447   1st Qu.: 85.38  \n                                     Median :4.653   Median :104.92  \n                                     Mean   :4.654   Mean   :111.70  \n                                     3rd Qu.:4.857   3rd Qu.:128.68  \n                                     Max.   :5.763   Max.   :318.34"
  },
  {
    "objectID": "index.html#dÃ©crivons-notre-dataset",
    "href": "index.html#dÃ©crivons-notre-dataset",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\nreport(df)\n\n\nThe data contains 3000 observations of the following 11 variables:\n\n  - year: n = 3000, Mean = 2005.79, SD = 2.03, Median = 2006.00, MAD = 2.97,\nrange: [2003, 2009], Skewness = 0.14, Kurtosis = -1.27, 0% missing\n  - age: n = 3000, Mean = 42.41, SD = 11.54, Median = 42.00, MAD = 13.34, range:\n[18, 80], Skewness = 0.15, Kurtosis = -0.45, 0% missing\n  - maritl: 5 levels, namely 1. Never Married (n = 648, 21.60%), 2. Married (n =\n2074, 69.13%), 3. Widowed (n = 19, 0.63%), 4. Divorced (n = 204, 6.80%) and 5.\nSeparated (n = 55, 1.83%)\n  - race: 4 levels, namely 1. White (n = 2480, 82.67%), 2. Black (n = 293,\n9.77%), 3. Asian (n = 190, 6.33%) and 4. Other (n = 37, 1.23%)\n  - education: 5 levels, namely 1. &lt; HS Grad (n = 268, 8.93%), 2. HS Grad (n =\n971, 32.37%), 3. Some College (n = 650, 21.67%), 4. College Grad (n = 685,\n22.83%) and 5. Advanced Degree (n = 426, 14.20%)\n  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle Atlantic (n\n= 3000, 100.00%), 3. East North Central (n = 0, 0.00%), 4. West North Central\n(n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%), 6. East South Central (n = 0,\n0.00%), 7. West South Central (n = 0, 0.00%), 8. Mountain (n = 0, 0.00%) and 9.\nPacific (n = 0, 0.00%)\n  - jobclass: 2 levels, namely 1. Industrial (n = 1544, 51.47%) and 2.\nInformation (n = 1456, 48.53%)\n  - health: 2 levels, namely 1. &lt;=Good (n = 858, 28.60%) and 2. &gt;=Very Good (n =\n2142, 71.40%)\n  - health_ins: 2 levels, namely 1. Yes (n = 2083, 69.43%) and 2. No (n = 917,\n30.57%)\n  - logwage: n = 3000, Mean = 4.65, SD = 0.35, Median = 4.65, MAD = 0.31, range:\n[3, 5.76], Skewness = -0.12, Kurtosis = 1.73, 0% missing\n  - wage: n = 3000, Mean = 111.70, SD = 41.73, Median = 104.92, MAD = 32.91,\nrange: [20.09, 318.34], Skewness = 1.68, Kurtosis = 4.84, 0% missing"
  },
  {
    "objectID": "index.html#vÃ©rifions-si-notre-dataset-Ã -des-donnÃ©es-manquantes",
    "href": "index.html#vÃ©rifions-si-notre-dataset-Ã -des-donnÃ©es-manquantes",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\nplot_intro(df)\n\n\n\n\n\nðŸ©º Pas de donnÃ©es manquantes\n\n\nCode\ndf |&gt; \n  correlate() |&gt; \n  plot()"
  },
  {
    "objectID": "index.html#crÃ©Ã©ons-un-modÃ¨le-de-regression-linÃ©aire",
    "href": "index.html#crÃ©Ã©ons-un-modÃ¨le-de-regression-linÃ©aire",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\n# ModÃ¨le de rÃ©gression linÃ©aire simple\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# PrÃ©diction du salaire en fonction de l'Ã¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049"
  },
  {
    "objectID": "index.html#visualisons-notre-dataset-avec-la-droite-de-rÃ©gression-et-notre-modÃ¨le-linÃ©aire",
    "href": "index.html#visualisons-notre-dataset-avec-la-droite-de-rÃ©gression-et-notre-modÃ¨le-linÃ©aire",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\n# CrÃ©er le graphique ggplot\np &lt;- ggplot(df, aes(x = age, y = wage)) + \n  geom_point(aes(color = education)) + \n  geom_smooth(method = lm) +\n  labs(title = \"Relation entre l'Ã¢ge et le salaire\", \n       x = \"Ã‚ge\", y = \"Salaire\") +\n  theme(plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5)) + \n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete() +\n  labs(title = \"Relation entre l'Ã¢ge et le salaire\") +\n  \n  # Ajouter une droite de rÃ©gression linÃ©aire\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") \n  \n# Convertir le graphique en un graphique Plotly interactif\nggplotly(p)\n\n\n\n\n\n\n\nPar exemple, lâ€™augmentation du salaire avec lâ€™Ã¢ge est beaucoup plus importante lorsque lâ€™on possÃ¨de au moins un diplÃ´me universitaire que si lâ€™on nâ€™a pas fait dâ€™Ã©tudes. Ainsi, Ã  la fin de notre vie, nous aurons un salaire impressionnant de 150 000 dollars, alors que sans aucune formation, nous ne dÃ©passerons jamais la barre des 100 000 dollars.\nIl semble donc que lâ€™Ã©ducation soit importante, et la pente le montre clairement ! Cependant, bien que la pente du diplÃ´me dâ€™Ã©tudes supÃ©rieures soit beaucoup plus faible, ce qui pourrait suggÃ©rer que lâ€™Ã©ducation nâ€™en vaut pas la peine, lâ€™ordonnÃ©e Ã  lâ€™origine raconte une autre histoire.\nEn effet, les personnes qui ont investi dans lâ€™Ã©ducation dÃ¨s le dÃ©part commencent leur vie avec le mÃªme salaire que celui que les personnes qui ont fait des Ã©tudes supÃ©rieures nâ€™atteignent quâ€™Ã  la fin de leur vie.\nExaminons attentivement ce modÃ¨le linÃ©aire. Il indique que la seule chose Ã  faire pour gagner beaucoup plus dâ€™argent est de vieillir. Mais pourquoi un groupe de personnes (nos outliers) gagne-t-il tellement plus que les autres ? et certaines personne aussi peu ? Et un modÃ¨le unique est-il en mesure dâ€™apprÃ©hender ces groupes ?\nSi lâ€™on examine le niveau dâ€™Ã©ducation de ces 3 000 personnes, on constate que la plupart des plus riches ont un diplÃ´me dâ€™Ã©tudes supÃ©rieures, tandis que la plupart des plus pauvres nâ€™ont quâ€™un diplÃ´me dâ€™Ã©tudes secondaires ou moins.\n\n\n\n\n\nCode\nm &lt;- lm(wage ~ education, data = df)\nplot_model(m, type = \"pred\")\n\n\n$education\n\n\n\n\n\nCode\nreport(m)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with education\n(formula: wage ~ education). The model explains a statistically significant and\nmoderate proportion of variance (R2 = 0.23, F(4, 2995) = 229.81, p &lt; .001, adj.\nR2 = 0.23). The model's intercept, corresponding to education = 1. &lt; HS Grad,\nis at 84.10 (95% CI [79.73, 88.48], t(2995) = 37.70, p &lt; .001). Within this\nmodel:\n\n  - The effect of education [2. HS Grad] is statistically significant and\npositive (beta = 11.68, 95% CI [6.74, 16.62], t(2995) = 4.63, p &lt; .001; Std.\nbeta = 0.28, 95% CI [0.16, 0.40])\n  - The effect of education [3. Some College] is statistically significant and\npositive (beta = 23.65, 95% CI [18.45, 28.85], t(2995) = 8.92, p &lt; .001; Std.\nbeta = 0.57, 95% CI [0.44, 0.69])\n  - The effect of education [4. College Grad] is statistically significant and\npositive (beta = 40.32, 95% CI [35.16, 45.48], t(2995) = 15.32, p &lt; .001; Std.\nbeta = 0.97, 95% CI [0.84, 1.09])\n  - The effect of education [5. Advanced Degree] is statistically significant and\npositive (beta = 66.81, 95% CI [61.23, 72.40], t(2995) = 23.46, p &lt; .001; Std.\nbeta = 1.60, 95% CI [1.47, 1.73])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nðŸ’¡Le tracÃ© de la prÃ©diction mâ€™indique immÃ©diatement lâ€™histoire. En effet, les personnes qui nâ€™ont mÃªme pas terminÃ© leurs Ã©tudes secondaires ont le salaire le plus bas par rapport Ã  tous les autres niveaux dâ€™Ã©ducation. En outre, nous pouvons constater que lâ€™augmentation du niveau dâ€™Ã©ducation se traduit par une augmentation des salaires. Lâ€™Ã©ducation est donc importante !"
  },
  {
    "objectID": "index.html#analysons-les-outliers-du-dataset",
    "href": "index.html#analysons-les-outliers-du-dataset",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\ndf |&gt; \n  select(wage) |&gt; \n  plot_outlier()\n\n\n\n\n\n\n\nCode\ndiagnose_outlier(df) |&gt; flextable()\n\n\n\nvariablesoutliers_cntoutliers_ratiooutliers_meanwith_meanwithout_meanyear00.00000002,005.7910002,005.79100age40.133333380.00000042.41466742.36449logwage1264.20000004.8456264.6539054.64550wage1103.6666667254.185937111.703608106.28041"
  },
  {
    "objectID": "index.html#splittons-notre-dataset-en-10-groupes-avec-group_by-et-nest",
    "href": "index.html#splittons-notre-dataset-en-10-groupes-avec-group_by-et-nest",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Avant de pouvoir modÃ©liser, nous devons diviser nos donnÃ©es en 10 groupes Ã  lâ€™aide de la fonction group_by(), puis verrouiller ces 10 groupes en 10 ensembles de donnÃ©es diffÃ©rents Ã  lâ€™aide de la fonction nest().\n\n\nCode\nnested_data &lt;- df |&gt;  \n  group_by(education, health_ins) |&gt; \n  nest() \n\nnested_data\n\n\n# A tibble: 10 Ã— 3\n# Groups:   education, health_ins [10]\n   education          health_ins data              \n   &lt;fct&gt;              &lt;fct&gt;      &lt;list&gt;            \n 1 1. &lt; HS Grad       2. No      &lt;tibble [144 Ã— 9]&gt;\n 2 4. College Grad    2. No      &lt;tibble [156 Ã— 9]&gt;\n 3 3. Some College    1. Yes     &lt;tibble [467 Ã— 9]&gt;\n 4 4. College Grad    1. Yes     &lt;tibble [529 Ã— 9]&gt;\n 5 2. HS Grad         1. Yes     &lt;tibble [612 Ã— 9]&gt;\n 6 2. HS Grad         2. No      &lt;tibble [359 Ã— 9]&gt;\n 7 5. Advanced Degree 2. No      &lt;tibble [75 Ã— 9]&gt; \n 8 5. Advanced Degree 1. Yes     &lt;tibble [351 Ã— 9]&gt;\n 9 3. Some College    2. No      &lt;tibble [183 Ã— 9]&gt;\n10 1. &lt; HS Grad       1. Yes     &lt;tibble [124 Ã— 9]&gt;\n\n\nDans un cadre de donnÃ©es imbriquÃ©, chaque ligne est une mÃ©ta-observation oÃ¹ les variables catÃ©gorielles â€œÃ©ducation et assurance maladieâ€ dÃ©finissent nos 10 groupes, tandis que la colonne-liste de 10 ensembles de donnÃ©es peut Ãªtre considÃ©rÃ©e comme 10 casiers contenant des observations individuelles appartenant uniquement Ã  une combinaison particuliÃ¨re dâ€™Ã©ducation et dâ€™assurance maladie."
  },
  {
    "objectID": "index.html#itÃ©rons-sur-chacun-des-datasets-crÃ©Ã©s-afin-de-crÃ©er-nos-modÃ¨les",
    "href": "index.html#itÃ©rons-sur-chacun-des-datasets-crÃ©Ã©s-afin-de-crÃ©er-nos-modÃ¨les",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\nnested_models &lt;- nested_data |&gt; \n  mutate(models  = map(data, ~ lm(wage ~ age, data = .)), \n         coefs   = map(models, tidy, conf.int = TRUE),\n         quality = map(models, glance),\n         preds   = map(models, augment),\n         performance = map(models, performance::check_model)) \n\nnested_models\n\n\n# A tibble: 10 Ã— 8\n# Groups:   education, health_ins [10]\n   education   health_ins data     models coefs    quality  preds    performance\n   &lt;fct&gt;       &lt;fct&gt;      &lt;list&gt;   &lt;list&gt; &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;     \n 1 1. &lt; HS Grâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 2 4. Collegeâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 3 3. Some Coâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 4 4. Collegeâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 5 2. HS Grad  1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 6 2. HS Grad  2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 7 5. Advanceâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 8 5. Advanceâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 9 3. Some Coâ€¦ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n10 1. &lt; HS Grâ€¦ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n\n\n\nmutate(data, models = map(data, ~ lm(wage ~ age, data = .))) : Cette ligne crÃ©e une nouvelle colonne appelÃ©e â€œmodelsâ€ dans le dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction lm() Ã  chaque Ã©lÃ©ment de la colonne â€œdataâ€, ajustant ainsi un modÃ¨le de rÃ©gression linÃ©aire avec â€œwageâ€ comme variable dÃ©pendante et â€œageâ€ comme variable indÃ©pendante.\nmutate(models, coefs = map(models, tidy, conf.int = TRUE)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œcoefsâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction tidy() du package broom Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction tidy() extrait les estimations des coefficients et les intervalles de confiance de chaque modÃ¨le de rÃ©gression linÃ©aire.\nmutate(models, quality = map(models, glance)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œqualityâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction glance() du package broom Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction glance() fournit un rÃ©sumÃ© de lâ€™ajustement du modÃ¨le, y compris diverses statistiques et mÃ©triques.\nmutate(models, preds = map(models, augment)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œpredsâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction augment() du package broom Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction augment() gÃ©nÃ¨re des valeurs prÃ©dites et dâ€™autres informations spÃ©cifiques au modÃ¨le.\nmutate(models, performance = map(models, performance::check_model)) : Cette ligne ajoute une nouvelle colonne appelÃ©e â€œperformanceâ€ au dataframe â€œnested_dataâ€. Elle utilise la fonction map() pour appliquer la fonction check_model() du package performance Ã  chaque Ã©lÃ©ment de la colonne â€œmodelsâ€. La fonction check_model() Ã©value les performances du modÃ¨le et fournit des diagnostics pertinents.\nEnfin, le code retourne le dataframe â€œnested_modelsâ€, qui contient la colonne â€œdataâ€ dâ€™origine, ainsi que les nouvelles colonnes â€œmodelsâ€, â€œcoefsâ€, â€œqualityâ€, â€œpredsâ€ et â€œperformanceâ€.\nNous pouvons map() library puur de tidyverse sur chaque mÃ©ta-observation de notre cadre de donnÃ©es imbriquÃ© et appliquer une rÃ©gression linÃ©aire Ã  chacun des 10 data-sets qui sont stockÃ©s dans la colonne de liste que nous avons appelÃ©e â€œdataâ€.\nDe plus, plutÃ´t que de laisser la liste des modÃ¨les comme des objets flottant librement , il est prÃ©fÃ©rable de stocker tous nos modÃ¨les dans la colonne-list suivante, appelons cette colonne-list â€œmodÃ¨lesâ€.\nEn outre, nous allons maintenant map() sur nos modÃ¨les afin dâ€™extraire les coefficients avec les IC Ã  95 %, les indicateurs de qualitÃ© du modÃ¨le et mÃªme les prÃ©dictions, et les stocker dans des colonnes distinctes."
  },
  {
    "objectID": "index.html#imprimons-les-informations-de-qualitÃ©-de-chacun-de-nos-modÃ¨les",
    "href": "index.html#imprimons-les-informations-de-qualitÃ©-de-chacun-de-nos-modÃ¨les",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\nnested_models |&gt;  \n  unnest(quality) |&gt;  \n  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |&gt; \n  arrange(adj.r.squared) |&gt; \n  mutate_if(is.numeric, ~ round(., 2)) |&gt;  \n  regulartable() |&gt;  \n  autofit()\n\n\n\neducationhealth_insr.squaredadj.r.squaredsigmastatisticp.valuelogLikAICBICnobsperformance4. College Grad2. No0.010.0035.771.310.25-778.391,562.771,571.92156[[check_model]]1. &lt; HS Grad2. No0.010.0020.141.450.23-635.691,277.381,286.29144[[check_model]]5. Advanced Degree1. Yes0.010.0153.333.530.06-1,892.833,791.663,803.24351[[check_model]]2. HS Grad1. Yes0.010.0127.567.510.01-2,897.115,800.225,813.47612[[check_model]]5. Advanced Degree2. No0.030.0151.511.890.17-401.04808.08815.0475[[check_model]]4. College Grad1. Yes0.020.0240.349.120.00-2,705.505,417.005,429.81529[[check_model]]1. &lt; HS Grad1. Yes0.040.0318.904.920.03-539.421,084.831,093.30124[[check_model]]2. HS Grad2. No0.050.0425.7817.000.00-1,674.983,355.963,367.61359[[check_model]]3. Some College1. Yes0.060.0626.9931.020.00-2,200.624,407.244,419.68467[[check_model]]3. Some College2. No0.170.1636.0436.510.00-914.661,835.311,844.94183[[check_model]]\n\n\nMaintenant que nous avons une liste de 10 modÃ¨les nous pouvons, par exemple :\n\nJeter un coup dâ€™Å“il au premier modÃ¨le ou Ã  ses coefficients et mÃªme ces performance\n\n\nCode\nreport(nested_models$models[[1]])\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically not significant and\nvery weak proportion of variance (R2 = 0.01, F(1, 142) = 1.45, p = 0.230, adj.\nR2 = 3.14e-03). The model's intercept, corresponding to age = 0, is at 69.80\n(95% CI [59.21, 80.39], t(142) = 13.03, p &lt; .001). Within this model:\n\n  - The effect of age is statistically non-significant and positive (beta = 0.16,\n95% CI [-0.10, 0.42], t(142) = 1.20, p = 0.230; Std. beta = 0.10, 95% CI\n[-0.06, 0.27])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nCode\nnested_models$models[[1]]\n\n\n\nCall:\nlm(formula = wage ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    69.8032       0.1572  \n\n\n\n\nCode\nnested_models$quality[[1]]\n\n\n# A tibble: 1 Ã— 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0101       0.00314  20.1      1.45   0.230     1  -636. 1277. 1286.\n# â„¹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nnested_models$performance[[1]]\n\n\n\n\n\n\nnous pouvons vÃ©rifier toutes les hypothÃ¨ses du second modÃ¨le en une seule fois en utilisant la fonction check_model() du package {performance},\nnous pouvons regarder la qualitÃ© du modÃ¨le, disons, un modÃ¨le NÂ°4 ou\nnous pouvons tracer les prÃ©dictions dâ€™un modÃ¨le NÂ°9 en utilisant la fonction plot_model() dâ€™un autre package Ã©tonnant {sjPlot}."
  },
  {
    "objectID": "index.html#crÃ©Ã©ons-un-modÃ¨le-de-rÃ©gression-linÃ©aire",
    "href": "index.html#crÃ©Ã©ons-un-modÃ¨le-de-rÃ©gression-linÃ©aire",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\n# ModÃ¨le de rÃ©gression linÃ©aire simple qui prÃ©dit les revenus en fonction de l'Ã¢ge\n\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# exemple de PrÃ©diction du salaire en fonction de l'Ã¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049"
  },
  {
    "objectID": "index.html#visualisons-nos-donnÃ©es",
    "href": "index.html#visualisons-nos-donnÃ©es",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\np  &lt;- df |&gt; \n  group_by(race) |&gt; \n  plot_frq(education) |&gt; \n    plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, race), education)): Not enough tags\nlabels in list. Using letters instead.\n\n\n\n\n\nðŸ’¡Par exemple, le sous-graphe C montre que la plupart des Afro-AmÃ©ricains de notre Ã©chantillon ont un niveau dâ€™Ã©ducation Ã©levÃ©.\n\n\n\n\n\nCode\nplot_grpfrq(\n  var.cnt = df$education,\n  var.grp = df$jobclass\n)\n\n\n\n\n\nðŸ’¡Par exemple, elle montre clairement que la plupart des personnes ayant un faible niveau dâ€™Ã©ducation travaillent dans des usines, tandis que les personnes ayant un niveau dâ€™Ã©ducation plus Ã©levÃ© travaillent dans le domaine de lâ€™information.\n\n\n\n\n\nCode\ndf |&gt; \n  group_by(jobclass) |&gt; \n  plot_frq(wage, type = \"histogram\", show.mean = TRUE, normal.curve = TRUE) |&gt; \n  plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, jobclass), wage, type = \"histogram\",\n: Not enough tags labels in list. Using letters instead.\n\n\n\n\n\nðŸ’¡Cette visualisation rÃ©vÃ¨le que les travailleurs de lâ€™industrie reÃ§oivent 103 000 dollars en moyenne, tandis que les informaticiens reÃ§oivent 17 000 dollars de plus."
  },
  {
    "objectID": "index.html#crÃ©ons-un-modÃ¨le-de-rÃ©gression-linÃ©aire",
    "href": "index.html#crÃ©ons-un-modÃ¨le-de-rÃ©gression-linÃ©aire",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Notre modÃ¨le prÃ©dit le salaire en fonction de lâ€™Ã¢ge\n\n\nCode\n# ModÃ¨le de rÃ©gression linÃ©aire simple qui prÃ©dit les revenus en fonction de l'Ã¢ge\n\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# exemple de PrÃ©diction du salaire en fonction de l'Ã¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049"
  },
  {
    "objectID": "index.html#maintenant-que-nous-avons-une-liste-de-10-modÃ¨les-nous-pouvons-par-exemple",
    "href": "index.html#maintenant-que-nous-avons-une-liste-de-10-modÃ¨les-nous-pouvons-par-exemple",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Jeter un coup dâ€™Å“il au premier modÃ¨le ou Ã  ses coefficients et mÃªme ces performance\n\n\nCode\nreport(nested_models$models[[1]])\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically not significant and\nvery weak proportion of variance (R2 = 0.01, F(1, 142) = 1.45, p = 0.230, adj.\nR2 = 3.14e-03). The model's intercept, corresponding to age = 0, is at 69.80\n(95% CI [59.21, 80.39], t(142) = 13.03, p &lt; .001). Within this model:\n\n  - The effect of age is statistically non-significant and positive (beta = 0.16,\n95% CI [-0.10, 0.42], t(142) = 1.20, p = 0.230; Std. beta = 0.10, 95% CI\n[-0.06, 0.27])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nCode\nnested_models$models[[1]]\n\n\n\nCall:\nlm(formula = wage ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    69.8032       0.1572  \n\n\n\n\nCode\nnested_models$quality[[1]]\n\n\n# A tibble: 1 Ã— 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0101       0.00314  20.1      1.45   0.230     1  -636. 1277. 1286.\n# â„¹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nnested_models$performance[[1]]\n\n\n\n\n\nnous pouvons vÃ©rifier toutes les hypothÃ¨ses du second modÃ¨le en une seule fois en utilisant la fonction check_model() du package {performance},\nnous pouvons regarder la qualitÃ© du modÃ¨le, disons, un modÃ¨le NÂ°4 ou\nnous pouvons tracer les prÃ©dictions dâ€™un modÃ¨le NÂ°9 en utilisant la fonction plot_model() dâ€™un autre package Ã©tonnant {sjPlot}."
  },
  {
    "objectID": "index.html#utilisons-la-fonction-unnest",
    "href": "index.html#utilisons-la-fonction-unnest",
    "title": "Projet Analyse de donnÃ©es en R, M2 IA School",
    "section": "",
    "text": "Code\nlibrary(flextable) # for a good looking table\nnested_models %&gt;%\n  unnest(coefs) %&gt;% \n  select(-data, -models, -quality, -preds) %&gt;% \n  mutate_if(is.numeric, ~ round(., 2)) %&gt;% \n  regulartable() %&gt;% \n  autofit()\n\n\n`mutate_if()` ignored the following grouping variables:\nâ€¢ Columns `education`, `health_ins`\n\n\n\neducationhealth_instermestimatestd.errorstatisticp.valueconf.lowconf.highperformance1. &lt; HS Grad2. No(Intercept)69.805.3613.030.0059.2180.39[[check_model]]1. &lt; HS Grad2. Noage0.160.131.200.23-0.100.42[[check_model]]4. College Grad2. No(Intercept)91.8410.488.760.0071.13112.55[[check_model]]4. College Grad2. Noage0.270.241.150.25-0.200.74[[check_model]]3. Some College1. Yes(Intercept)86.144.9317.480.0076.4695.83[[check_model]]3. Some College1. Yesage0.630.115.570.000.410.85[[check_model]]4. College Grad1. Yes(Intercept)109.067.3614.830.0094.61123.51[[check_model]]4. College Grad1. Yesage0.500.173.020.000.180.83[[check_model]]2. HS Grad1. Yes(Intercept)90.594.4720.250.0081.8099.37[[check_model]]2. HS Grad1. Yesage0.270.102.740.010.080.46[[check_model]]2. HS Grad2. No(Intercept)66.754.4914.860.0057.9275.58[[check_model]]2. HS Grad2. Noage0.450.114.120.000.240.67[[check_model]]5. Advanced Degree2. No(Intercept)97.0625.913.750.0045.43148.70[[check_model]]5. Advanced Degree2. Noage0.730.531.380.17-0.331.80[[check_model]]5. Advanced Degree1. Yes(Intercept)131.1513.0210.080.00105.55156.75[[check_model]]5. Advanced Degree1. Yesage0.540.291.880.06-0.031.10[[check_model]]3. Some College2. No(Intercept)44.848.745.130.0027.5962.08[[check_model]]3. Some College2. Noage1.340.226.040.000.901.77[[check_model]]1. &lt; HS Grad1. Yes(Intercept)78.746.9111.390.0065.0692.43[[check_model]]1. &lt; HS Grad1. Yesage0.330.152.220.030.040.62[[check_model]]\n\n\n\n\n\n\n\nCode\nnested_models |&gt;  \n  unnest(quality) |&gt;  \n  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |&gt; \n  arrange(adj.r.squared) |&gt; \n  mutate_if(is.numeric, ~ round(., 2)) |&gt;  \n  regulartable() |&gt;  \n  autofit()\n\n\n\neducationhealth_insr.squaredadj.r.squaredsigmastatisticp.valuelogLikAICBICnobsperformance4. College Grad2. No0.010.0035.771.310.25-778.391,562.771,571.92156[[check_model]]1. &lt; HS Grad2. No0.010.0020.141.450.23-635.691,277.381,286.29144[[check_model]]5. Advanced Degree1. Yes0.010.0153.333.530.06-1,892.833,791.663,803.24351[[check_model]]2. HS Grad1. Yes0.010.0127.567.510.01-2,897.115,800.225,813.47612[[check_model]]5. Advanced Degree2. No0.030.0151.511.890.17-401.04808.08815.0475[[check_model]]4. College Grad1. Yes0.020.0240.349.120.00-2,705.505,417.005,429.81529[[check_model]]1. &lt; HS Grad1. Yes0.040.0318.904.920.03-539.421,084.831,093.30124[[check_model]]2. HS Grad2. No0.050.0425.7817.000.00-1,674.983,355.963,367.61359[[check_model]]3. Some College1. Yes0.060.0626.9931.020.00-2,200.624,407.244,419.68467[[check_model]]3. Some College2. No0.170.1636.0436.510.00-914.661,835.311,844.94183[[check_model]]\n\n\n\n\nCode\nunnested_preds &lt;- \n  nested_models |&gt; \n  unnest(preds)\n\n\n\n\nCode\nggplot(df, aes(x = age, y = wage, group = health_ins)) +\n   geom_point(aes(color = health_ins), alpha = 0.2, shape = 1) +\n   geom_smooth(method = \"lm\", size = 2) +\n   facet_grid(. ~ education, scales = \"free\") +\n   geom_line(data = unnested_preds, aes(y = .fitted, age, color = health_ins)) \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead."
  }
]