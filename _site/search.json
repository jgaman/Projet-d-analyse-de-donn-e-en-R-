[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "√† Propos",
    "section": "",
    "text": "Description du dataset"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Durant cette exploration nous t√¢cherons de r√©pondre aux questions suivantes :\n\nComment expliquer la diff√©rence de salaire entre indivus ?\nEst ce que le niveau d'√©tude a un impact sur les revenus de nos individus ?\nPeut-on pr√©dire quel sera le salaire d'un individu gr√¢ce √† son niveau d'√©tude ?\n\n\n\n\n\nCode\nlibrary(tidyverse) # tout ce dont on a besoin pour modifier et analyser nos donn√©es\nlibrary(ISLR) #contient notre dataset Wage\nlibrary(flextable) # pour de belles pr√©sentations sous forme de tables\nlibrary(dlookr) # Analyse exploratoire de donn√©es, traitement des donn√©es manquantes et corr√©lation\nlibrary(ggstatsplot) # de belles visualisations statistiques et sommaire statistique de notre dataset\nlibrary(tidymodels) # Machine learning \nlibrary(report) # ce package d√©crit automatiquement nos models et autres dataset\nlibrary(gtsummary) # de beau sommaire\nlibrary(DataExplorer) # rev√®le les donn√©es manquantes et permet de les remplacer\nlibrary(plotly) #interactive visualisation\nlibrary(performance) #performance et comparaison de mod√®les\nlibrary(sjPlot)\nlibrary(broom)   # pour tidy(), glance() & augment() fonctions\n\n\n\n\n\n\n\nCode\ndf &lt;- Wage\nsummary(df)\n\n\n      year           age                     maritl           race     \n Min.   :2003   Min.   :18.00   1. Never Married: 648   1. White:2480  \n 1st Qu.:2004   1st Qu.:33.75   2. Married      :2074   2. Black: 293  \n Median :2006   Median :42.00   3. Widowed      :  19   3. Asian: 190  \n Mean   :2006   Mean   :42.41   4. Divorced     : 204   4. Other:  37  \n 3rd Qu.:2008   3rd Qu.:51.00   5. Separated    :  55                  \n Max.   :2009   Max.   :80.00                                          \n                                                                       \n              education                     region               jobclass   \n 1. &lt; HS Grad      :268   2. Middle Atlantic   :3000   1. Industrial :1544  \n 2. HS Grad        :971   1. New England       :   0   2. Information:1456  \n 3. Some College   :650   3. East North Central:   0                        \n 4. College Grad   :685   4. West North Central:   0                        \n 5. Advanced Degree:426   5. South Atlantic    :   0                        \n                          6. East South Central:   0                        \n                          (Other)              :   0                        \n            health      health_ins      logwage           wage       \n 1. &lt;=Good     : 858   1. Yes:2083   Min.   :3.000   Min.   : 20.09  \n 2. &gt;=Very Good:2142   2. No : 917   1st Qu.:4.447   1st Qu.: 85.38  \n                                     Median :4.653   Median :104.92  \n                                     Mean   :4.654   Mean   :111.70  \n                                     3rd Qu.:4.857   3rd Qu.:128.68  \n                                     Max.   :5.763   Max.   :318.34  \n                                                                     \n\n\n\n\n\n\n\nCode\nreport(df)\n\n\nThe data contains 3000 observations of the following 11 variables:\n\n  - year: n = 3000, Mean = 2005.79, SD = 2.03, Median = 2006.00, MAD = 2.97,\nrange: [2003, 2009], Skewness = 0.14, Kurtosis = -1.27, 0% missing\n  - age: n = 3000, Mean = 42.41, SD = 11.54, Median = 42.00, MAD = 13.34, range:\n[18, 80], Skewness = 0.15, Kurtosis = -0.45, 0% missing\n  - maritl: 5 levels, namely 1. Never Married (n = 648, 21.60%), 2. Married (n =\n2074, 69.13%), 3. Widowed (n = 19, 0.63%), 4. Divorced (n = 204, 6.80%) and 5.\nSeparated (n = 55, 1.83%)\n  - race: 4 levels, namely 1. White (n = 2480, 82.67%), 2. Black (n = 293,\n9.77%), 3. Asian (n = 190, 6.33%) and 4. Other (n = 37, 1.23%)\n  - education: 5 levels, namely 1. &lt; HS Grad (n = 268, 8.93%), 2. HS Grad (n =\n971, 32.37%), 3. Some College (n = 650, 21.67%), 4. College Grad (n = 685,\n22.83%) and 5. Advanced Degree (n = 426, 14.20%)\n  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle Atlantic (n\n= 3000, 100.00%), 3. East North Central (n = 0, 0.00%), 4. West North Central\n(n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%), 6. East South Central (n = 0,\n0.00%), 7. West South Central (n = 0, 0.00%), 8. Mountain (n = 0, 0.00%) and 9.\nPacific (n = 0, 0.00%)\n  - jobclass: 2 levels, namely 1. Industrial (n = 1544, 51.47%) and 2.\nInformation (n = 1456, 48.53%)\n  - health: 2 levels, namely 1. &lt;=Good (n = 858, 28.60%) and 2. &gt;=Very Good (n =\n2142, 71.40%)\n  - health_ins: 2 levels, namely 1. Yes (n = 2083, 69.43%) and 2. No (n = 917,\n30.57%)\n  - logwage: n = 3000, Mean = 4.65, SD = 0.35, Median = 4.65, MAD = 0.31, range:\n[3, 5.76], Skewness = -0.12, Kurtosis = 1.73, 0% missing\n  - wage: n = 3000, Mean = 111.70, SD = 41.73, Median = 104.92, MAD = 32.91,\nrange: [20.09, 318.34], Skewness = 1.68, Kurtosis = 4.84, 0% missing\n\n\n\n\n\n\n\nCode\nplot_intro(df)\n\n\n\n\n\nü©∫ Pas de donn√©es manquantes\n\n\nCode\ndf |&gt; \n  correlate() |&gt; \n  plot()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np  &lt;- df |&gt; \n  group_by(race) |&gt; \n  plot_frq(education) |&gt; \n    plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, race), education)): Not enough tags\nlabels in list. Using letters instead.\n\n\n\n\n\nüí°Par exemple, le sous-graphe C montre que la plupart des Afro-Am√©ricains de notre √©chantillon ont un niveau d‚Äô√©ducation √©lev√©.\n\n\n\n\n\nCode\nplot_grpfrq(\n  var.cnt = df$education,\n  var.grp = df$jobclass\n)\n\n\n\n\n\nüí°Par exemple, elle montre clairement que la plupart des personnes ayant un faible niveau d‚Äô√©ducation travaillent dans des usines, tandis que les personnes ayant un niveau d‚Äô√©ducation plus √©lev√© travaillent dans le domaine de l‚Äôinformation.\n\n\n\n\n\nCode\ndf |&gt; \n  group_by(jobclass) |&gt; \n  plot_frq(wage, type = \"histogram\", show.mean = TRUE, normal.curve = TRUE) |&gt; \n  plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, jobclass), wage, type = \"histogram\",\n: Not enough tags labels in list. Using letters instead.\n\n\n\n\n\nüí°Cette visualisation r√©v√®le que les travailleurs de l‚Äôindustrie re√ßoivent 103 000 dollars en moyenne, tandis que les informaticiens re√ßoivent 17 000 dollars de plus.\n\n\n\n\nNotre mod√®le pr√©dit le salaire en fonction de l‚Äô√¢ge\n\n\nCode\n# Mod√®le de r√©gression lin√©aire simple qui pr√©dit les revenus en fonction de l'√¢ge\n\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# exemple de Pr√©diction du salaire en fonction de l'√¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049 \n\n\n\n\n\n\n\nCode\n# Cr√©er le graphique ggplot\np &lt;- ggplot(df, aes(x = age, y = wage)) + \n  geom_point(aes(color = education)) + \n  geom_smooth(method = lm) +\n  labs(title = \"Relation entre l'√¢ge et le salaire\", \n       x = \"√Çge\", y = \"Salaire\") +\n  theme(plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5)) + \n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete() +\n  labs(title = \"Relation entre l'√¢ge et le salaire\") +\n  \n  # Ajouter une droite de r√©gression lin√©aire\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") \n  \n# Convertir le graphique en un graphique Plotly interactif\nggplotly(p)\n\n\n\n\n\n\n\nPar exemple, l‚Äôaugmentation du salaire avec l‚Äô√¢ge est beaucoup plus importante lorsque l‚Äôon poss√®de au moins un dipl√¥me universitaire que si l‚Äôon n‚Äôa pas fait d‚Äô√©tudes. Ainsi, √† la fin de notre vie, nous aurons un salaire impressionnant de 150 000 dollars, alors que sans aucune formation, nous ne d√©passerons jamais la barre des 100 000 dollars.\nIl semble donc que l‚Äô√©ducation soit importante, et la pente le montre clairement ! Cependant, bien que la pente du dipl√¥me d‚Äô√©tudes sup√©rieures soit beaucoup plus faible, ce qui pourrait sugg√©rer que l‚Äô√©ducation n‚Äôen vaut pas la peine, l‚Äôordonn√©e √† l‚Äôorigine raconte une autre histoire.\nEn effet, les personnes qui ont investi dans l‚Äô√©ducation d√®s le d√©part commencent leur vie avec le m√™me salaire que celui que les personnes qui ont fait des √©tudes sup√©rieures n‚Äôatteignent qu‚Äô√† la fin de leur vie.\nExaminons attentivement ce mod√®le lin√©aire. Il indique que la seule chose √† faire pour gagner beaucoup plus d‚Äôargent est de vieillir. Mais pourquoi un groupe de personnes (nos outliers) gagne-t-il tellement plus que les autres ? et certaines personne aussi peu ? Et un mod√®le unique est-il en mesure d‚Äôappr√©hender ces groupes ?\nSi l‚Äôon examine le niveau d‚Äô√©ducation de ces 3 000 personnes, on constate que la plupart des plus riches ont un dipl√¥me d‚Äô√©tudes sup√©rieures, tandis que la plupart des plus pauvres n‚Äôont qu‚Äôun dipl√¥me d‚Äô√©tudes secondaires ou moins.\n\n\n\n\n\nCode\nm &lt;- lm(wage ~ education, data = df)\nplot_model(m, type = \"pred\")\n\n\n$education\n\n\n\n\n\nCode\nreport(m)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with education\n(formula: wage ~ education). The model explains a statistically significant and\nmoderate proportion of variance (R2 = 0.23, F(4, 2995) = 229.81, p &lt; .001, adj.\nR2 = 0.23). The model's intercept, corresponding to education = 1. &lt; HS Grad,\nis at 84.10 (95% CI [79.73, 88.48], t(2995) = 37.70, p &lt; .001). Within this\nmodel:\n\n  - The effect of education [2. HS Grad] is statistically significant and\npositive (beta = 11.68, 95% CI [6.74, 16.62], t(2995) = 4.63, p &lt; .001; Std.\nbeta = 0.28, 95% CI [0.16, 0.40])\n  - The effect of education [3. Some College] is statistically significant and\npositive (beta = 23.65, 95% CI [18.45, 28.85], t(2995) = 8.92, p &lt; .001; Std.\nbeta = 0.57, 95% CI [0.44, 0.69])\n  - The effect of education [4. College Grad] is statistically significant and\npositive (beta = 40.32, 95% CI [35.16, 45.48], t(2995) = 15.32, p &lt; .001; Std.\nbeta = 0.97, 95% CI [0.84, 1.09])\n  - The effect of education [5. Advanced Degree] is statistically significant and\npositive (beta = 66.81, 95% CI [61.23, 72.40], t(2995) = 23.46, p &lt; .001; Std.\nbeta = 1.60, 95% CI [1.47, 1.73])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nüí°Le trac√© de la pr√©diction m‚Äôindique imm√©diatement l‚Äôhistoire. En effet, les personnes qui n‚Äôont m√™me pas termin√© leurs √©tudes secondaires ont le salaire le plus bas par rapport √† tous les autres niveaux d‚Äô√©ducation. En outre, nous pouvons constater que l‚Äôaugmentation du niveau d‚Äô√©ducation se traduit par une augmentation des salaires. L‚Äô√©ducation est donc importante !\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(wage) |&gt; \n  plot_outlier()\n\n\n\n\n\n\n\nCode\ndiagnose_outlier(df) |&gt; flextable()\n\n\n\nvariablesoutliers_cntoutliers_ratiooutliers_meanwith_meanwithout_meanyear00.00000002,005.7910002,005.79100age40.133333380.00000042.41466742.36449logwage1264.20000004.8456264.6539054.64550wage1103.6666667254.185937111.703608106.28041\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(age, wage, education, jobclass, health_ins) |&gt; \n  tbl_summary(by = education) \n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1. &lt; HS Grad, N = 2681\n      2. HS Grad, N = 9711\n      3. Some College, N = 6501\n      4. College Grad, N = 6851\n      5. Advanced Degree, N = 4261\n    \n  \n  \n    age\n42 (33, 50)\n42 (33, 50)\n40 (32, 49)\n43 (34, 51)\n44 (38, 53)\n    wage\n81 (70, 97)\n94 (78, 110)\n105 (89, 121)\n119 (100, 143)\n142 (117, 171)\n    jobclass\n\n\n\n\n\n    ¬†¬†¬†¬†1. Industrial\n190 (71%)\n636 (65%)\n342 (53%)\n274 (40%)\n102 (24%)\n    ¬†¬†¬†¬†2. Information\n78 (29%)\n335 (35%)\n308 (47%)\n411 (60%)\n324 (76%)\n    health_ins\n\n\n\n\n\n    ¬†¬†¬†¬†1. Yes\n124 (46%)\n612 (63%)\n467 (72%)\n529 (77%)\n351 (82%)\n    ¬†¬†¬†¬†2. No\n144 (54%)\n359 (37%)\n183 (28%)\n156 (23%)\n75 (18%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nDans le premier cas, 144 personnes n‚Äôont pas d‚Äô√©ducation (‚Äú1. &lt; HS Grad‚Äù) et pas d‚Äôassurance maladie (‚Äú2. No‚Äù).\n\n\n\nAvant de pouvoir mod√©liser, nous devons diviser nos donn√©es en 10 groupes √† l‚Äôaide de la fonction group_by(), puis verrouiller ces 10 groupes en 10 ensembles de donn√©es diff√©rents √† l‚Äôaide de la fonction nest().\n\n\nCode\nnested_data &lt;- df |&gt;  \n  group_by(education, health_ins) |&gt; \n  nest() \n\nnested_data\n\n\n# A tibble: 10 √ó 3\n# Groups:   education, health_ins [10]\n   education          health_ins data              \n   &lt;fct&gt;              &lt;fct&gt;      &lt;list&gt;            \n 1 1. &lt; HS Grad       2. No      &lt;tibble [144 √ó 9]&gt;\n 2 4. College Grad    2. No      &lt;tibble [156 √ó 9]&gt;\n 3 3. Some College    1. Yes     &lt;tibble [467 √ó 9]&gt;\n 4 4. College Grad    1. Yes     &lt;tibble [529 √ó 9]&gt;\n 5 2. HS Grad         1. Yes     &lt;tibble [612 √ó 9]&gt;\n 6 2. HS Grad         2. No      &lt;tibble [359 √ó 9]&gt;\n 7 5. Advanced Degree 2. No      &lt;tibble [75 √ó 9]&gt; \n 8 5. Advanced Degree 1. Yes     &lt;tibble [351 √ó 9]&gt;\n 9 3. Some College    2. No      &lt;tibble [183 √ó 9]&gt;\n10 1. &lt; HS Grad       1. Yes     &lt;tibble [124 √ó 9]&gt;\n\n\nDans un cadre de donn√©es imbriqu√©, chaque ligne est une m√©ta-observation o√π les variables cat√©gorielles ‚Äú√©ducation et assurance maladie‚Äù d√©finissent nos 10 groupes, tandis que la colonne-liste de 10 ensembles de donn√©es peut √™tre consid√©r√©e comme 10 casiers contenant des observations individuelles appartenant uniquement √† une combinaison particuli√®re d‚Äô√©ducation et d‚Äôassurance maladie.\n\n\n\n\n\nCode\nnested_models &lt;- nested_data |&gt; \n  mutate(models  = map(data, ~ lm(wage ~ age, data = .)), \n         coefs   = map(models, tidy, conf.int = TRUE),\n         quality = map(models, glance),\n         preds   = map(models, augment),\n         performance = map(models, performance::check_model)) \n\nnested_models\n\n\n# A tibble: 10 √ó 8\n# Groups:   education, health_ins [10]\n   education   health_ins data     models coefs    quality  preds    performance\n   &lt;fct&gt;       &lt;fct&gt;      &lt;list&gt;   &lt;list&gt; &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;     \n 1 1. &lt; HS Gr‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 2 4. College‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 3 3. Some Co‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 4 4. College‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 5 2. HS Grad  1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 6 2. HS Grad  2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 7 5. Advance‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 8 5. Advance‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 9 3. Some Co‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n10 1. &lt; HS Gr‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n\n\n\nmutate(data, models = map(data, ~ lm(wage ~ age, data = .))) : Cette ligne cr√©e une nouvelle colonne appel√©e ‚Äúmodels‚Äù dans le dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction lm() √† chaque √©l√©ment de la colonne ‚Äúdata‚Äù, ajustant ainsi un mod√®le de r√©gression lin√©aire avec ‚Äúwage‚Äù comme variable d√©pendante et ‚Äúage‚Äù comme variable ind√©pendante.\nmutate(models, coefs = map(models, tidy, conf.int = TRUE)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúcoefs‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction tidy() du package broom √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction tidy() extrait les estimations des coefficients et les intervalles de confiance de chaque mod√®le de r√©gression lin√©aire.\nmutate(models, quality = map(models, glance)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúquality‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction glance() du package broom √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction glance() fournit un r√©sum√© de l‚Äôajustement du mod√®le, y compris diverses statistiques et m√©triques.\nmutate(models, preds = map(models, augment)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúpreds‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction augment() du package broom √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction augment() g√©n√®re des valeurs pr√©dites et d‚Äôautres informations sp√©cifiques au mod√®le.\nmutate(models, performance = map(models, performance::check_model)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúperformance‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction check_model() du package performance √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction check_model() √©value les performances du mod√®le et fournit des diagnostics pertinents.\nEnfin, le code retourne le dataframe ‚Äúnested_models‚Äù, qui contient la colonne ‚Äúdata‚Äù d‚Äôorigine, ainsi que les nouvelles colonnes ‚Äúmodels‚Äù, ‚Äúcoefs‚Äù, ‚Äúquality‚Äù, ‚Äúpreds‚Äù et ‚Äúperformance‚Äù.\nNous pouvons map() library puur de tidyverse sur chaque m√©ta-observation de notre cadre de donn√©es imbriqu√© et appliquer une r√©gression lin√©aire √† chacun des 10 data-sets qui sont stock√©s dans la colonne de liste que nous avons appel√©e ‚Äúdata‚Äù.\nDe plus, plut√¥t que de laisser la liste des mod√®les comme des objets flottant librement , il est pr√©f√©rable de stocker tous nos mod√®les dans la colonne-list suivante, appelons cette colonne-list ‚Äúmod√®les‚Äù.\nEn outre, nous allons maintenant map() sur nos mod√®les afin d‚Äôextraire les coefficients avec les IC √† 95 %, les indicateurs de qualit√© du mod√®le et m√™me les pr√©dictions, et les stocker dans des colonnes distinctes.\n\n\n\n\nJeter un coup d‚Äô≈ìil au premier mod√®le ou √† ses coefficients et m√™me ces performance\n\n\nCode\nreport(nested_models$models[[1]])\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically not significant and\nvery weak proportion of variance (R2 = 0.01, F(1, 142) = 1.45, p = 0.230, adj.\nR2 = 3.14e-03). The model's intercept, corresponding to age = 0, is at 69.80\n(95% CI [59.21, 80.39], t(142) = 13.03, p &lt; .001). Within this model:\n\n  - The effect of age is statistically non-significant and positive (beta = 0.16,\n95% CI [-0.10, 0.42], t(142) = 1.20, p = 0.230; Std. beta = 0.10, 95% CI\n[-0.06, 0.27])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nCode\nnested_models$models[[1]]\n\n\n\nCall:\nlm(formula = wage ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    69.8032       0.1572  \n\n\n\n\nCode\nnested_models$quality[[1]]\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0101       0.00314  20.1      1.45   0.230     1  -636. 1277. 1286.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nnested_models$performance[[1]]\n\n\n\n\n\nnous pouvons v√©rifier toutes les hypoth√®ses du second mod√®le en une seule fois en utilisant la fonction check_model() du package {performance},\nnous pouvons regarder la qualit√© du mod√®le, disons, un mod√®le N¬∞4 ou\nnous pouvons tracer les pr√©dictions d‚Äôun mod√®le N¬∞9 en utilisant la fonction plot_model() d‚Äôun autre package √©tonnant {sjPlot}.\n\n\n\n\n\n\n\nCode\nlibrary(flextable) # for a good looking table\nnested_models %&gt;%\n  unnest(coefs) %&gt;% \n  select(-data, -models, -quality, -preds) %&gt;% \n  mutate_if(is.numeric, ~ round(., 2)) %&gt;% \n  regulartable() %&gt;% \n  autofit()\n\n\n`mutate_if()` ignored the following grouping variables:\n‚Ä¢ Columns `education`, `health_ins`\n\n\n\neducationhealth_instermestimatestd.errorstatisticp.valueconf.lowconf.highperformance1. &lt; HS Grad2. No(Intercept)69.805.3613.030.0059.2180.39[[check_model]]1. &lt; HS Grad2. Noage0.160.131.200.23-0.100.42[[check_model]]4. College Grad2. No(Intercept)91.8410.488.760.0071.13112.55[[check_model]]4. College Grad2. Noage0.270.241.150.25-0.200.74[[check_model]]3. Some College1. Yes(Intercept)86.144.9317.480.0076.4695.83[[check_model]]3. Some College1. Yesage0.630.115.570.000.410.85[[check_model]]4. College Grad1. Yes(Intercept)109.067.3614.830.0094.61123.51[[check_model]]4. College Grad1. Yesage0.500.173.020.000.180.83[[check_model]]2. HS Grad1. Yes(Intercept)90.594.4720.250.0081.8099.37[[check_model]]2. HS Grad1. Yesage0.270.102.740.010.080.46[[check_model]]2. HS Grad2. No(Intercept)66.754.4914.860.0057.9275.58[[check_model]]2. HS Grad2. Noage0.450.114.120.000.240.67[[check_model]]5. Advanced Degree2. No(Intercept)97.0625.913.750.0045.43148.70[[check_model]]5. Advanced Degree2. Noage0.730.531.380.17-0.331.80[[check_model]]5. Advanced Degree1. Yes(Intercept)131.1513.0210.080.00105.55156.75[[check_model]]5. Advanced Degree1. Yesage0.540.291.880.06-0.031.10[[check_model]]3. Some College2. No(Intercept)44.848.745.130.0027.5962.08[[check_model]]3. Some College2. Noage1.340.226.040.000.901.77[[check_model]]1. &lt; HS Grad1. Yes(Intercept)78.746.9111.390.0065.0692.43[[check_model]]1. &lt; HS Grad1. Yesage0.330.152.220.030.040.62[[check_model]]\n\n\n\n\n\n\n\nCode\nnested_models |&gt;  \n  unnest(quality) |&gt;  \n  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |&gt; \n  arrange(adj.r.squared) |&gt; \n  mutate_if(is.numeric, ~ round(., 2)) |&gt;  \n  regulartable() |&gt;  \n  autofit()\n\n\n\neducationhealth_insr.squaredadj.r.squaredsigmastatisticp.valuelogLikAICBICnobsperformance4. College Grad2. No0.010.0035.771.310.25-778.391,562.771,571.92156[[check_model]]1. &lt; HS Grad2. No0.010.0020.141.450.23-635.691,277.381,286.29144[[check_model]]5. Advanced Degree1. Yes0.010.0153.333.530.06-1,892.833,791.663,803.24351[[check_model]]2. HS Grad1. Yes0.010.0127.567.510.01-2,897.115,800.225,813.47612[[check_model]]5. Advanced Degree2. No0.030.0151.511.890.17-401.04808.08815.0475[[check_model]]4. College Grad1. Yes0.020.0240.349.120.00-2,705.505,417.005,429.81529[[check_model]]1. &lt; HS Grad1. Yes0.040.0318.904.920.03-539.421,084.831,093.30124[[check_model]]2. HS Grad2. No0.050.0425.7817.000.00-1,674.983,355.963,367.61359[[check_model]]3. Some College1. Yes0.060.0626.9931.020.00-2,200.624,407.244,419.68467[[check_model]]3. Some College2. No0.170.1636.0436.510.00-914.661,835.311,844.94183[[check_model]]\n\n\n\n\nCode\nunnested_preds &lt;- \n  nested_models |&gt; \n  unnest(preds)\n\n\n\n\nCode\nggplot(df, aes(x = age, y = wage, group = health_ins)) +\n   geom_point(aes(color = health_ins), alpha = 0.2, shape = 1) +\n   geom_smooth(method = \"lm\", size = 2) +\n   facet_grid(. ~ education, scales = \"free\") +\n   geom_line(data = unnested_preds, aes(y = .fitted, age, color = health_ins)) \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead."
  },
  {
    "objectID": "about.html#format",
    "href": "about.html#format",
    "title": "√† Propos",
    "section": "Format",
    "text": "Format\nA data frame with 3000 observations on the following 11 variables.\n\nyear\n\nYear that wage information was recorded\n\nage\n\nAge of worker\n\nmaritl\n\nA factor with levels 1. Never Married 2. Married 3. Widowed 4. Divorced and 5. Separated indicating marital status\n\nrace\n\nA factor with levels 1. White 2. Black 3. Asian and 4. Other indicating race\n\neducation\n\nA factor with levels 1. &lt; HS Grad 2. HS Grad 3. Some College 4. College Grad and 5. Advanced Degree indicating education level\n\nregion\n\nRegion of the country (mid-atlantic only)\n\njobclass\n\nA factor with levels 1. Industrial and 2. Information indicating type of job\n\nhealth\n\nA factor with levels 1. &lt;=Good and 2. &gt;=Very Good indicating health level of worker\n\nhealth_ins\n\nA factor with levels 1. Yes and 2. No indicating whether worker has health insurance\n\nlogwage\n\nLog of workers wage\n\nwage\n\nWorkers raw wage"
  },
  {
    "objectID": "index.html#sommaire-de-notre-dataset",
    "href": "index.html#sommaire-de-notre-dataset",
    "title": "Projet Analyse de donn√©es en R",
    "section": "Sommaire de notre dataset",
    "text": "Sommaire de notre dataset\n\ndf |> \n  select(age, wage, education, jobclass, race) |> \n  tbl_summary(by = education) \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1. < HS Grad, N = 2681\n      2. HS Grad, N = 9711\n      3. Some College, N = 6501\n      4. College Grad, N = 6851\n      5. Advanced Degree, N = 4261\n    \n  \n  \n    age\n42 (33, 50)\n42 (33, 50)\n40 (32, 49)\n43 (34, 51)\n44 (38, 53)\n    wage\n81 (70, 97)\n94 (78, 110)\n105 (89, 121)\n119 (100, 143)\n142 (117, 171)\n    jobclass\n\n\n\n\n\n    ¬†¬†¬†¬†1. Industrial\n190 (71%)\n636 (65%)\n342 (53%)\n274 (40%)\n102 (24%)\n    ¬†¬†¬†¬†2. Information\n78 (29%)\n335 (35%)\n308 (47%)\n411 (60%)\n324 (76%)\n    race\n\n\n\n\n\n    ¬†¬†¬†¬†1. White\n211 (79%)\n822 (85%)\n532 (82%)\n576 (84%)\n339 (80%)\n    ¬†¬†¬†¬†2. Black\n31 (12%)\n105 (11%)\n92 (14%)\n40 (5.8%)\n25 (5.9%)\n    ¬†¬†¬†¬†3. Asian\n15 (5.6%)\n31 (3.2%)\n18 (2.8%)\n66 (9.6%)\n60 (14%)\n    ¬†¬†¬†¬†4. Other\n11 (4.1%)\n13 (1.3%)\n8 (1.2%)\n3 (0.4%)\n2 (0.5%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)"
  },
  {
    "objectID": "index.html#decrivons-notre-dataset",
    "href": "index.html#decrivons-notre-dataset",
    "title": "Projet Analyse de donn√©es en R",
    "section": "Decrivons notre dataset",
    "text": "Decrivons notre dataset\n\ndf |> \n  select(age, wage, education, jobclass, race) |> \n  group_by(education) |>\n  report() |> \n  summary()\n\nThe data contains 3000 observations, grouped by education, of the following 5\nvariables:\n\n- 1. < HS Grad (n = 268):\n  - age: Mean = 41.79, SD = 12.61, range: [18, 75]\n  - wage: Mean = 84.10, SD = 21.58, range: [20.93, 152.22]\n  - jobclass: 2 levels, namely 1. Industrial (n = 190) and 2. Information (n =\n78)\n  - race: 4 levels, namely 1. White (n = 211), 2. Black (n = 31), 3. Asian (n =\n15) and 4. Other (n = 11)\n\n- 2. HS Grad (n = 971):\n  - age: Mean = 42.22, SD = 12.02, range: [18, 80]\n  - wage: Mean = 95.78, SD = 28.57, range: [23.27, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 636) and 2. Information (n =\n335)\n  - race: 4 levels, namely 1. White (n = 822), 2. Black (n = 105), 3. Asian (n =\n31) and 4. Other (n = 13)\n\n- 3. Some College (n = 650):\n  - age: Mean = 40.89, SD = 11.52, range: [18, 80]\n  - wage: Mean = 107.76, SD = 32.47, range: [20.09, 314.33]\n  - jobclass: 2 levels, namely 1. Industrial (n = 342) and 2. Information (n =\n308)\n  - race: 4 levels, namely 1. White (n = 532), 2. Black (n = 92), 3. Asian (n =\n18) and 4. Other (n = 8)\n\n- 4. College Grad (n = 685):\n  - age: Mean = 42.77, SD = 10.90, range: [22, 76]\n  - wage: Mean = 124.43, SD = 41.19, range: [32.37, 281.75]\n  - jobclass: 2 levels, namely 1. Industrial (n = 274) and 2. Information (n =\n411)\n  - race: 4 levels, namely 1. White (n = 576), 2. Black (n = 40), 3. Asian (n =\n66) and 4. Other (n = 3)\n\n- 5. Advanced Degree (n = 426):\n  - age: Mean = 45.01, SD = 10.26, range: [25, 76]\n  - wage: Mean = 150.92, SD = 53.90, range: [38.61, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 102) and 2. Information (n =\n324)\n  - race: 4 levels, namely 1. White (n = 339), 2. Black (n = 25), 3. Asian (n =\n60) and 4. Other (n = 2)"
  },
  {
    "objectID": "index.html#tableau-crois√©-de-nos-individus-rang√©s-par-niveau-d√©ducation",
    "href": "index.html#tableau-crois√©-de-nos-individus-rang√©s-par-niveau-d√©ducation",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\ndf |&gt; \n  select(age, wage, education, jobclass, health_ins) |&gt; \n  tbl_summary(by = education) \n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1. &lt; HS Grad, N = 2681\n      2. HS Grad, N = 9711\n      3. Some College, N = 6501\n      4. College Grad, N = 6851\n      5. Advanced Degree, N = 4261\n    \n  \n  \n    age\n42 (33, 50)\n42 (33, 50)\n40 (32, 49)\n43 (34, 51)\n44 (38, 53)\n    wage\n81 (70, 97)\n94 (78, 110)\n105 (89, 121)\n119 (100, 143)\n142 (117, 171)\n    jobclass\n\n\n\n\n\n    ¬†¬†¬†¬†1. Industrial\n190 (71%)\n636 (65%)\n342 (53%)\n274 (40%)\n102 (24%)\n    ¬†¬†¬†¬†2. Information\n78 (29%)\n335 (35%)\n308 (47%)\n411 (60%)\n324 (76%)\n    health_ins\n\n\n\n\n\n    ¬†¬†¬†¬†1. Yes\n124 (46%)\n612 (63%)\n467 (72%)\n529 (77%)\n351 (82%)\n    ¬†¬†¬†¬†2. No\n144 (54%)\n359 (37%)\n183 (28%)\n156 (23%)\n75 (18%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nDans le premier cas, 144 personnes n‚Äôont pas d‚Äô√©ducation (‚Äú1. &lt; HS Grad‚Äù) et pas d‚Äôassurance maladie (‚Äú2. No‚Äù)."
  },
  {
    "objectID": "index.html#d√©crivons-ce-tableau-crois√©",
    "href": "index.html#d√©crivons-ce-tableau-crois√©",
    "title": "Projet Analyse de donn√©es en R",
    "section": "D√©crivons ce Tableau crois√©",
    "text": "D√©crivons ce Tableau crois√©\n\ndf |> \n  select(age, wage, education, jobclass, race) |> \n  group_by(education) |>\n  report() |> \n  summary()\n\nThe data contains 3000 observations, grouped by education, of the following 5\nvariables:\n\n- 1. < HS Grad (n = 268):\n  - age: Mean = 41.79, SD = 12.61, range: [18, 75]\n  - wage: Mean = 84.10, SD = 21.58, range: [20.93, 152.22]\n  - jobclass: 2 levels, namely 1. Industrial (n = 190) and 2. Information (n =\n78)\n  - race: 4 levels, namely 1. White (n = 211), 2. Black (n = 31), 3. Asian (n =\n15) and 4. Other (n = 11)\n\n- 2. HS Grad (n = 971):\n  - age: Mean = 42.22, SD = 12.02, range: [18, 80]\n  - wage: Mean = 95.78, SD = 28.57, range: [23.27, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 636) and 2. Information (n =\n335)\n  - race: 4 levels, namely 1. White (n = 822), 2. Black (n = 105), 3. Asian (n =\n31) and 4. Other (n = 13)\n\n- 3. Some College (n = 650):\n  - age: Mean = 40.89, SD = 11.52, range: [18, 80]\n  - wage: Mean = 107.76, SD = 32.47, range: [20.09, 314.33]\n  - jobclass: 2 levels, namely 1. Industrial (n = 342) and 2. Information (n =\n308)\n  - race: 4 levels, namely 1. White (n = 532), 2. Black (n = 92), 3. Asian (n =\n18) and 4. Other (n = 8)\n\n- 4. College Grad (n = 685):\n  - age: Mean = 42.77, SD = 10.90, range: [22, 76]\n  - wage: Mean = 124.43, SD = 41.19, range: [32.37, 281.75]\n  - jobclass: 2 levels, namely 1. Industrial (n = 274) and 2. Information (n =\n411)\n  - race: 4 levels, namely 1. White (n = 576), 2. Black (n = 40), 3. Asian (n =\n66) and 4. Other (n = 3)\n\n- 5. Advanced Degree (n = 426):\n  - age: Mean = 45.01, SD = 10.26, range: [25, 76]\n  - wage: Mean = 150.92, SD = 53.90, range: [38.61, 318.34]\n  - jobclass: 2 levels, namely 1. Industrial (n = 102) and 2. Information (n =\n324)\n  - race: 4 levels, namely 1. White (n = 339), 2. Black (n = 25), 3. Asian (n =\n60) and 4. Other (n = 2)"
  },
  {
    "objectID": "index.html#installation-des-diff√©rentes-librairies",
    "href": "index.html#installation-des-diff√©rentes-librairies",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\nlibrary(tidyverse) # tout ce dont on a besoin pour modifier et analyser nos donn√©es\nlibrary(ISLR) #contient notre dataset Wage\nlibrary(flextable) # pour de belles pr√©sentations sous forme de tables\nlibrary(dlookr) # Analyse exploratoire de donn√©es, traitement des donn√©es manquantes et corr√©lation\nlibrary(ggstatsplot) # de belles visualisations statistiques et sommaire statistique de notre dataset\nlibrary(tidymodels) # Machine learning \nlibrary(report) # ce package d√©crit automatiquement nos models et autres dataset\nlibrary(gtsummary) # de beau sommaire\nlibrary(DataExplorer) # rev√®le les donn√©es manquantes et permet de les remplacer\nlibrary(plotly) #interactive visualisation\nlibrary(performance) #performance et comparaison de mod√®les\nlibrary(sjPlot)\nlibrary(broom)   # pour tidy(), glance() & augment() fonctions"
  },
  {
    "objectID": "index.html#importons-notre-dataset",
    "href": "index.html#importons-notre-dataset",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\ndf &lt;- Wage\nsummary(df)\n\n\n      year           age                     maritl           race     \n Min.   :2003   Min.   :18.00   1. Never Married: 648   1. White:2480  \n 1st Qu.:2004   1st Qu.:33.75   2. Married      :2074   2. Black: 293  \n Median :2006   Median :42.00   3. Widowed      :  19   3. Asian: 190  \n Mean   :2006   Mean   :42.41   4. Divorced     : 204   4. Other:  37  \n 3rd Qu.:2008   3rd Qu.:51.00   5. Separated    :  55                  \n Max.   :2009   Max.   :80.00                                          \n                                                                       \n              education                     region               jobclass   \n 1. &lt; HS Grad      :268   2. Middle Atlantic   :3000   1. Industrial :1544  \n 2. HS Grad        :971   1. New England       :   0   2. Information:1456  \n 3. Some College   :650   3. East North Central:   0                        \n 4. College Grad   :685   4. West North Central:   0                        \n 5. Advanced Degree:426   5. South Atlantic    :   0                        \n                          6. East South Central:   0                        \n                          (Other)              :   0                        \n            health      health_ins      logwage           wage       \n 1. &lt;=Good     : 858   1. Yes:2083   Min.   :3.000   Min.   : 20.09  \n 2. &gt;=Very Good:2142   2. No : 917   1st Qu.:4.447   1st Qu.: 85.38  \n                                     Median :4.653   Median :104.92  \n                                     Mean   :4.654   Mean   :111.70  \n                                     3rd Qu.:4.857   3rd Qu.:128.68  \n                                     Max.   :5.763   Max.   :318.34"
  },
  {
    "objectID": "index.html#d√©crivons-notre-dataset",
    "href": "index.html#d√©crivons-notre-dataset",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\nreport(df)\n\n\nThe data contains 3000 observations of the following 11 variables:\n\n  - year: n = 3000, Mean = 2005.79, SD = 2.03, Median = 2006.00, MAD = 2.97,\nrange: [2003, 2009], Skewness = 0.14, Kurtosis = -1.27, 0% missing\n  - age: n = 3000, Mean = 42.41, SD = 11.54, Median = 42.00, MAD = 13.34, range:\n[18, 80], Skewness = 0.15, Kurtosis = -0.45, 0% missing\n  - maritl: 5 levels, namely 1. Never Married (n = 648, 21.60%), 2. Married (n =\n2074, 69.13%), 3. Widowed (n = 19, 0.63%), 4. Divorced (n = 204, 6.80%) and 5.\nSeparated (n = 55, 1.83%)\n  - race: 4 levels, namely 1. White (n = 2480, 82.67%), 2. Black (n = 293,\n9.77%), 3. Asian (n = 190, 6.33%) and 4. Other (n = 37, 1.23%)\n  - education: 5 levels, namely 1. &lt; HS Grad (n = 268, 8.93%), 2. HS Grad (n =\n971, 32.37%), 3. Some College (n = 650, 21.67%), 4. College Grad (n = 685,\n22.83%) and 5. Advanced Degree (n = 426, 14.20%)\n  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle Atlantic (n\n= 3000, 100.00%), 3. East North Central (n = 0, 0.00%), 4. West North Central\n(n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%), 6. East South Central (n = 0,\n0.00%), 7. West South Central (n = 0, 0.00%), 8. Mountain (n = 0, 0.00%) and 9.\nPacific (n = 0, 0.00%)\n  - jobclass: 2 levels, namely 1. Industrial (n = 1544, 51.47%) and 2.\nInformation (n = 1456, 48.53%)\n  - health: 2 levels, namely 1. &lt;=Good (n = 858, 28.60%) and 2. &gt;=Very Good (n =\n2142, 71.40%)\n  - health_ins: 2 levels, namely 1. Yes (n = 2083, 69.43%) and 2. No (n = 917,\n30.57%)\n  - logwage: n = 3000, Mean = 4.65, SD = 0.35, Median = 4.65, MAD = 0.31, range:\n[3, 5.76], Skewness = -0.12, Kurtosis = 1.73, 0% missing\n  - wage: n = 3000, Mean = 111.70, SD = 41.73, Median = 104.92, MAD = 32.91,\nrange: [20.09, 318.34], Skewness = 1.68, Kurtosis = 4.84, 0% missing"
  },
  {
    "objectID": "index.html#v√©rifions-si-notre-dataset-√†-des-donn√©es-manquantes",
    "href": "index.html#v√©rifions-si-notre-dataset-√†-des-donn√©es-manquantes",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\nplot_intro(df)\n\n\n\n\n\nü©∫ Pas de donn√©es manquantes\n\n\nCode\ndf |&gt; \n  correlate() |&gt; \n  plot()"
  },
  {
    "objectID": "index.html#cr√©√©ons-un-mod√®le-de-regression-lin√©aire",
    "href": "index.html#cr√©√©ons-un-mod√®le-de-regression-lin√©aire",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\n# Mod√®le de r√©gression lin√©aire simple\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# Pr√©diction du salaire en fonction de l'√¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049"
  },
  {
    "objectID": "index.html#visualisons-notre-dataset-avec-la-droite-de-r√©gression-et-notre-mod√®le-lin√©aire",
    "href": "index.html#visualisons-notre-dataset-avec-la-droite-de-r√©gression-et-notre-mod√®le-lin√©aire",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\n# Cr√©er le graphique ggplot\np &lt;- ggplot(df, aes(x = age, y = wage)) + \n  geom_point(aes(color = education)) + \n  geom_smooth(method = lm) +\n  labs(title = \"Relation entre l'√¢ge et le salaire\", \n       x = \"√Çge\", y = \"Salaire\") +\n  theme(plot.title = element_text(size = 18, face = \"bold\", hjust = 0.5)) + \n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete() +\n  labs(title = \"Relation entre l'√¢ge et le salaire\") +\n  \n  # Ajouter une droite de r√©gression lin√©aire\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") \n  \n# Convertir le graphique en un graphique Plotly interactif\nggplotly(p)\n\n\n\n\n\n\n\nPar exemple, l‚Äôaugmentation du salaire avec l‚Äô√¢ge est beaucoup plus importante lorsque l‚Äôon poss√®de au moins un dipl√¥me universitaire que si l‚Äôon n‚Äôa pas fait d‚Äô√©tudes. Ainsi, √† la fin de notre vie, nous aurons un salaire impressionnant de 150 000 dollars, alors que sans aucune formation, nous ne d√©passerons jamais la barre des 100 000 dollars.\nIl semble donc que l‚Äô√©ducation soit importante, et la pente le montre clairement ! Cependant, bien que la pente du dipl√¥me d‚Äô√©tudes sup√©rieures soit beaucoup plus faible, ce qui pourrait sugg√©rer que l‚Äô√©ducation n‚Äôen vaut pas la peine, l‚Äôordonn√©e √† l‚Äôorigine raconte une autre histoire.\nEn effet, les personnes qui ont investi dans l‚Äô√©ducation d√®s le d√©part commencent leur vie avec le m√™me salaire que celui que les personnes qui ont fait des √©tudes sup√©rieures n‚Äôatteignent qu‚Äô√† la fin de leur vie.\nExaminons attentivement ce mod√®le lin√©aire. Il indique que la seule chose √† faire pour gagner beaucoup plus d‚Äôargent est de vieillir. Mais pourquoi un groupe de personnes (nos outliers) gagne-t-il tellement plus que les autres ? et certaines personne aussi peu ? Et un mod√®le unique est-il en mesure d‚Äôappr√©hender ces groupes ?\nSi l‚Äôon examine le niveau d‚Äô√©ducation de ces 3 000 personnes, on constate que la plupart des plus riches ont un dipl√¥me d‚Äô√©tudes sup√©rieures, tandis que la plupart des plus pauvres n‚Äôont qu‚Äôun dipl√¥me d‚Äô√©tudes secondaires ou moins.\n\n\n\n\n\nCode\nm &lt;- lm(wage ~ education, data = df)\nplot_model(m, type = \"pred\")\n\n\n$education\n\n\n\n\n\nCode\nreport(m)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with education\n(formula: wage ~ education). The model explains a statistically significant and\nmoderate proportion of variance (R2 = 0.23, F(4, 2995) = 229.81, p &lt; .001, adj.\nR2 = 0.23). The model's intercept, corresponding to education = 1. &lt; HS Grad,\nis at 84.10 (95% CI [79.73, 88.48], t(2995) = 37.70, p &lt; .001). Within this\nmodel:\n\n  - The effect of education [2. HS Grad] is statistically significant and\npositive (beta = 11.68, 95% CI [6.74, 16.62], t(2995) = 4.63, p &lt; .001; Std.\nbeta = 0.28, 95% CI [0.16, 0.40])\n  - The effect of education [3. Some College] is statistically significant and\npositive (beta = 23.65, 95% CI [18.45, 28.85], t(2995) = 8.92, p &lt; .001; Std.\nbeta = 0.57, 95% CI [0.44, 0.69])\n  - The effect of education [4. College Grad] is statistically significant and\npositive (beta = 40.32, 95% CI [35.16, 45.48], t(2995) = 15.32, p &lt; .001; Std.\nbeta = 0.97, 95% CI [0.84, 1.09])\n  - The effect of education [5. Advanced Degree] is statistically significant and\npositive (beta = 66.81, 95% CI [61.23, 72.40], t(2995) = 23.46, p &lt; .001; Std.\nbeta = 1.60, 95% CI [1.47, 1.73])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nüí°Le trac√© de la pr√©diction m‚Äôindique imm√©diatement l‚Äôhistoire. En effet, les personnes qui n‚Äôont m√™me pas termin√© leurs √©tudes secondaires ont le salaire le plus bas par rapport √† tous les autres niveaux d‚Äô√©ducation. En outre, nous pouvons constater que l‚Äôaugmentation du niveau d‚Äô√©ducation se traduit par une augmentation des salaires. L‚Äô√©ducation est donc importante !"
  },
  {
    "objectID": "index.html#analysons-les-outliers-du-dataset",
    "href": "index.html#analysons-les-outliers-du-dataset",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\ndf |&gt; \n  select(wage) |&gt; \n  plot_outlier()\n\n\n\n\n\n\n\nCode\ndiagnose_outlier(df) |&gt; flextable()\n\n\n\nvariablesoutliers_cntoutliers_ratiooutliers_meanwith_meanwithout_meanyear00.00000002,005.7910002,005.79100age40.133333380.00000042.41466742.36449logwage1264.20000004.8456264.6539054.64550wage1103.6666667254.185937111.703608106.28041"
  },
  {
    "objectID": "index.html#splittons-notre-dataset-en-10-groupes-avec-group_by-et-nest",
    "href": "index.html#splittons-notre-dataset-en-10-groupes-avec-group_by-et-nest",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Avant de pouvoir mod√©liser, nous devons diviser nos donn√©es en 10 groupes √† l‚Äôaide de la fonction group_by(), puis verrouiller ces 10 groupes en 10 ensembles de donn√©es diff√©rents √† l‚Äôaide de la fonction nest().\n\n\nCode\nnested_data &lt;- df |&gt;  \n  group_by(education, health_ins) |&gt; \n  nest() \n\nnested_data\n\n\n# A tibble: 10 √ó 3\n# Groups:   education, health_ins [10]\n   education          health_ins data              \n   &lt;fct&gt;              &lt;fct&gt;      &lt;list&gt;            \n 1 1. &lt; HS Grad       2. No      &lt;tibble [144 √ó 9]&gt;\n 2 4. College Grad    2. No      &lt;tibble [156 √ó 9]&gt;\n 3 3. Some College    1. Yes     &lt;tibble [467 √ó 9]&gt;\n 4 4. College Grad    1. Yes     &lt;tibble [529 √ó 9]&gt;\n 5 2. HS Grad         1. Yes     &lt;tibble [612 √ó 9]&gt;\n 6 2. HS Grad         2. No      &lt;tibble [359 √ó 9]&gt;\n 7 5. Advanced Degree 2. No      &lt;tibble [75 √ó 9]&gt; \n 8 5. Advanced Degree 1. Yes     &lt;tibble [351 √ó 9]&gt;\n 9 3. Some College    2. No      &lt;tibble [183 √ó 9]&gt;\n10 1. &lt; HS Grad       1. Yes     &lt;tibble [124 √ó 9]&gt;\n\n\nDans un cadre de donn√©es imbriqu√©, chaque ligne est une m√©ta-observation o√π les variables cat√©gorielles ‚Äú√©ducation et assurance maladie‚Äù d√©finissent nos 10 groupes, tandis que la colonne-liste de 10 ensembles de donn√©es peut √™tre consid√©r√©e comme 10 casiers contenant des observations individuelles appartenant uniquement √† une combinaison particuli√®re d‚Äô√©ducation et d‚Äôassurance maladie."
  },
  {
    "objectID": "index.html#it√©rons-sur-chacun-des-datasets-cr√©√©s-afin-de-cr√©er-nos-mod√®les",
    "href": "index.html#it√©rons-sur-chacun-des-datasets-cr√©√©s-afin-de-cr√©er-nos-mod√®les",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\nnested_models &lt;- nested_data |&gt; \n  mutate(models  = map(data, ~ lm(wage ~ age, data = .)), \n         coefs   = map(models, tidy, conf.int = TRUE),\n         quality = map(models, glance),\n         preds   = map(models, augment),\n         performance = map(models, performance::check_model)) \n\nnested_models\n\n\n# A tibble: 10 √ó 8\n# Groups:   education, health_ins [10]\n   education   health_ins data     models coefs    quality  preds    performance\n   &lt;fct&gt;       &lt;fct&gt;      &lt;list&gt;   &lt;list&gt; &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;     \n 1 1. &lt; HS Gr‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 2 4. College‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 3 3. Some Co‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 4 4. College‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 5 2. HS Grad  1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 6 2. HS Grad  2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 7 5. Advance‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 8 5. Advance‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n 9 3. Some Co‚Ä¶ 2. No      &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n10 1. &lt; HS Gr‚Ä¶ 1. Yes     &lt;tibble&gt; &lt;lm&gt;   &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;chck_mdl&gt; \n\n\n\nmutate(data, models = map(data, ~ lm(wage ~ age, data = .))) : Cette ligne cr√©e une nouvelle colonne appel√©e ‚Äúmodels‚Äù dans le dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction lm() √† chaque √©l√©ment de la colonne ‚Äúdata‚Äù, ajustant ainsi un mod√®le de r√©gression lin√©aire avec ‚Äúwage‚Äù comme variable d√©pendante et ‚Äúage‚Äù comme variable ind√©pendante.\nmutate(models, coefs = map(models, tidy, conf.int = TRUE)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúcoefs‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction tidy() du package broom √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction tidy() extrait les estimations des coefficients et les intervalles de confiance de chaque mod√®le de r√©gression lin√©aire.\nmutate(models, quality = map(models, glance)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúquality‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction glance() du package broom √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction glance() fournit un r√©sum√© de l‚Äôajustement du mod√®le, y compris diverses statistiques et m√©triques.\nmutate(models, preds = map(models, augment)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúpreds‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction augment() du package broom √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction augment() g√©n√®re des valeurs pr√©dites et d‚Äôautres informations sp√©cifiques au mod√®le.\nmutate(models, performance = map(models, performance::check_model)) : Cette ligne ajoute une nouvelle colonne appel√©e ‚Äúperformance‚Äù au dataframe ‚Äúnested_data‚Äù. Elle utilise la fonction map() pour appliquer la fonction check_model() du package performance √† chaque √©l√©ment de la colonne ‚Äúmodels‚Äù. La fonction check_model() √©value les performances du mod√®le et fournit des diagnostics pertinents.\nEnfin, le code retourne le dataframe ‚Äúnested_models‚Äù, qui contient la colonne ‚Äúdata‚Äù d‚Äôorigine, ainsi que les nouvelles colonnes ‚Äúmodels‚Äù, ‚Äúcoefs‚Äù, ‚Äúquality‚Äù, ‚Äúpreds‚Äù et ‚Äúperformance‚Äù.\nNous pouvons map() library puur de tidyverse sur chaque m√©ta-observation de notre cadre de donn√©es imbriqu√© et appliquer une r√©gression lin√©aire √† chacun des 10 data-sets qui sont stock√©s dans la colonne de liste que nous avons appel√©e ‚Äúdata‚Äù.\nDe plus, plut√¥t que de laisser la liste des mod√®les comme des objets flottant librement , il est pr√©f√©rable de stocker tous nos mod√®les dans la colonne-list suivante, appelons cette colonne-list ‚Äúmod√®les‚Äù.\nEn outre, nous allons maintenant map() sur nos mod√®les afin d‚Äôextraire les coefficients avec les IC √† 95 %, les indicateurs de qualit√© du mod√®le et m√™me les pr√©dictions, et les stocker dans des colonnes distinctes."
  },
  {
    "objectID": "index.html#imprimons-les-informations-de-qualit√©-de-chacun-de-nos-mod√®les",
    "href": "index.html#imprimons-les-informations-de-qualit√©-de-chacun-de-nos-mod√®les",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\nnested_models |&gt;  \n  unnest(quality) |&gt;  \n  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |&gt; \n  arrange(adj.r.squared) |&gt; \n  mutate_if(is.numeric, ~ round(., 2)) |&gt;  \n  regulartable() |&gt;  \n  autofit()\n\n\n\neducationhealth_insr.squaredadj.r.squaredsigmastatisticp.valuelogLikAICBICnobsperformance4. College Grad2. No0.010.0035.771.310.25-778.391,562.771,571.92156[[check_model]]1. &lt; HS Grad2. No0.010.0020.141.450.23-635.691,277.381,286.29144[[check_model]]5. Advanced Degree1. Yes0.010.0153.333.530.06-1,892.833,791.663,803.24351[[check_model]]2. HS Grad1. Yes0.010.0127.567.510.01-2,897.115,800.225,813.47612[[check_model]]5. Advanced Degree2. No0.030.0151.511.890.17-401.04808.08815.0475[[check_model]]4. College Grad1. Yes0.020.0240.349.120.00-2,705.505,417.005,429.81529[[check_model]]1. &lt; HS Grad1. Yes0.040.0318.904.920.03-539.421,084.831,093.30124[[check_model]]2. HS Grad2. No0.050.0425.7817.000.00-1,674.983,355.963,367.61359[[check_model]]3. Some College1. Yes0.060.0626.9931.020.00-2,200.624,407.244,419.68467[[check_model]]3. Some College2. No0.170.1636.0436.510.00-914.661,835.311,844.94183[[check_model]]\n\n\nMaintenant que nous avons une liste de 10 mod√®les nous pouvons, par exemple :\n\nJeter un coup d‚Äô≈ìil au premier mod√®le ou √† ses coefficients et m√™me ces performance\n\n\nCode\nreport(nested_models$models[[1]])\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically not significant and\nvery weak proportion of variance (R2 = 0.01, F(1, 142) = 1.45, p = 0.230, adj.\nR2 = 3.14e-03). The model's intercept, corresponding to age = 0, is at 69.80\n(95% CI [59.21, 80.39], t(142) = 13.03, p &lt; .001). Within this model:\n\n  - The effect of age is statistically non-significant and positive (beta = 0.16,\n95% CI [-0.10, 0.42], t(142) = 1.20, p = 0.230; Std. beta = 0.10, 95% CI\n[-0.06, 0.27])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nCode\nnested_models$models[[1]]\n\n\n\nCall:\nlm(formula = wage ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    69.8032       0.1572  \n\n\n\n\nCode\nnested_models$quality[[1]]\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0101       0.00314  20.1      1.45   0.230     1  -636. 1277. 1286.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nnested_models$performance[[1]]\n\n\n\n\n\n\nnous pouvons v√©rifier toutes les hypoth√®ses du second mod√®le en une seule fois en utilisant la fonction check_model() du package {performance},\nnous pouvons regarder la qualit√© du mod√®le, disons, un mod√®le N¬∞4 ou\nnous pouvons tracer les pr√©dictions d‚Äôun mod√®le N¬∞9 en utilisant la fonction plot_model() d‚Äôun autre package √©tonnant {sjPlot}."
  },
  {
    "objectID": "index.html#cr√©√©ons-un-mod√®le-de-r√©gression-lin√©aire",
    "href": "index.html#cr√©√©ons-un-mod√®le-de-r√©gression-lin√©aire",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\n# Mod√®le de r√©gression lin√©aire simple qui pr√©dit les revenus en fonction de l'√¢ge\n\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# exemple de Pr√©diction du salaire en fonction de l'√¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049"
  },
  {
    "objectID": "index.html#visualisons-nos-donn√©es",
    "href": "index.html#visualisons-nos-donn√©es",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\np  &lt;- df |&gt; \n  group_by(race) |&gt; \n  plot_frq(education) |&gt; \n    plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, race), education)): Not enough tags\nlabels in list. Using letters instead.\n\n\n\n\n\nüí°Par exemple, le sous-graphe C montre que la plupart des Afro-Am√©ricains de notre √©chantillon ont un niveau d‚Äô√©ducation √©lev√©.\n\n\n\n\n\nCode\nplot_grpfrq(\n  var.cnt = df$education,\n  var.grp = df$jobclass\n)\n\n\n\n\n\nüí°Par exemple, elle montre clairement que la plupart des personnes ayant un faible niveau d‚Äô√©ducation travaillent dans des usines, tandis que les personnes ayant un niveau d‚Äô√©ducation plus √©lev√© travaillent dans le domaine de l‚Äôinformation.\n\n\n\n\n\nCode\ndf |&gt; \n  group_by(jobclass) |&gt; \n  plot_frq(wage, type = \"histogram\", show.mean = TRUE, normal.curve = TRUE) |&gt; \n  plot_grid()\n\n\nWarning in plot_grid(plot_frq(group_by(df, jobclass), wage, type = \"histogram\",\n: Not enough tags labels in list. Using letters instead.\n\n\n\n\n\nüí°Cette visualisation r√©v√®le que les travailleurs de l‚Äôindustrie re√ßoivent 103 000 dollars en moyenne, tandis que les informaticiens re√ßoivent 17 000 dollars de plus."
  },
  {
    "objectID": "index.html#cr√©ons-un-mod√®le-de-r√©gression-lin√©aire",
    "href": "index.html#cr√©ons-un-mod√®le-de-r√©gression-lin√©aire",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Notre mod√®le pr√©dit le salaire en fonction de l‚Äô√¢ge\n\n\nCode\n# Mod√®le de r√©gression lin√©aire simple qui pr√©dit les revenus en fonction de l'√¢ge\n\nlm.fit &lt;- lm(wage ~ age, data = df)\nreport(lm.fit)\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically significant and weak\nproportion of variance (R2 = 0.04, F(1, 2998) = 119.31, p &lt; .001, adj. R2 =\n0.04). The model's intercept, corresponding to age = 0, is at 81.70 (95% CI\n[76.12, 87.29], t(2998) = 28.71, p &lt; .001). Within this model:\n\n  - The effect of age is statistically significant and positive (beta = 0.71, 95%\nCI [0.58, 0.83], t(2998) = 10.92, p &lt; .001; Std. beta = 0.20, 95% CI [0.16,\n0.23])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nCode\n# exemple de Pr√©diction du salaire en fonction de l'√¢ge\nnewdata &lt;- data.frame(age = 55)\npredict(lm.fit, newdata)\n\n\n       1 \n120.6049"
  },
  {
    "objectID": "index.html#maintenant-que-nous-avons-une-liste-de-10-mod√®les-nous-pouvons-par-exemple",
    "href": "index.html#maintenant-que-nous-avons-une-liste-de-10-mod√®les-nous-pouvons-par-exemple",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Jeter un coup d‚Äô≈ìil au premier mod√®le ou √† ses coefficients et m√™me ces performance\n\n\nCode\nreport(nested_models$models[[1]])\n\n\nWe fitted a linear model (estimated using OLS) to predict wage with age\n(formula: wage ~ age). The model explains a statistically not significant and\nvery weak proportion of variance (R2 = 0.01, F(1, 142) = 1.45, p = 0.230, adj.\nR2 = 3.14e-03). The model's intercept, corresponding to age = 0, is at 69.80\n(95% CI [59.21, 80.39], t(142) = 13.03, p &lt; .001). Within this model:\n\n  - The effect of age is statistically non-significant and positive (beta = 0.16,\n95% CI [-0.10, 0.42], t(142) = 1.20, p = 0.230; Std. beta = 0.10, 95% CI\n[-0.06, 0.27])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\n\n\nCode\nnested_models$models[[1]]\n\n\n\nCall:\nlm(formula = wage ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    69.8032       0.1572  \n\n\n\n\nCode\nnested_models$quality[[1]]\n\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0101       0.00314  20.1      1.45   0.230     1  -636. 1277. 1286.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nCode\nnested_models$performance[[1]]\n\n\n\n\n\nnous pouvons v√©rifier toutes les hypoth√®ses du second mod√®le en une seule fois en utilisant la fonction check_model() du package {performance},\nnous pouvons regarder la qualit√© du mod√®le, disons, un mod√®le N¬∞4 ou\nnous pouvons tracer les pr√©dictions d‚Äôun mod√®le N¬∞9 en utilisant la fonction plot_model() d‚Äôun autre package √©tonnant {sjPlot}."
  },
  {
    "objectID": "index.html#utilisons-la-fonction-unnest",
    "href": "index.html#utilisons-la-fonction-unnest",
    "title": "Projet Analyse de donn√©es en R, M2 IA School",
    "section": "",
    "text": "Code\nlibrary(flextable) # for a good looking table\nnested_models %&gt;%\n  unnest(coefs) %&gt;% \n  select(-data, -models, -quality, -preds) %&gt;% \n  mutate_if(is.numeric, ~ round(., 2)) %&gt;% \n  regulartable() %&gt;% \n  autofit()\n\n\n`mutate_if()` ignored the following grouping variables:\n‚Ä¢ Columns `education`, `health_ins`\n\n\n\neducationhealth_instermestimatestd.errorstatisticp.valueconf.lowconf.highperformance1. &lt; HS Grad2. No(Intercept)69.805.3613.030.0059.2180.39[[check_model]]1. &lt; HS Grad2. Noage0.160.131.200.23-0.100.42[[check_model]]4. College Grad2. No(Intercept)91.8410.488.760.0071.13112.55[[check_model]]4. College Grad2. Noage0.270.241.150.25-0.200.74[[check_model]]3. Some College1. Yes(Intercept)86.144.9317.480.0076.4695.83[[check_model]]3. Some College1. Yesage0.630.115.570.000.410.85[[check_model]]4. College Grad1. Yes(Intercept)109.067.3614.830.0094.61123.51[[check_model]]4. College Grad1. Yesage0.500.173.020.000.180.83[[check_model]]2. HS Grad1. Yes(Intercept)90.594.4720.250.0081.8099.37[[check_model]]2. HS Grad1. Yesage0.270.102.740.010.080.46[[check_model]]2. HS Grad2. No(Intercept)66.754.4914.860.0057.9275.58[[check_model]]2. HS Grad2. Noage0.450.114.120.000.240.67[[check_model]]5. Advanced Degree2. No(Intercept)97.0625.913.750.0045.43148.70[[check_model]]5. Advanced Degree2. Noage0.730.531.380.17-0.331.80[[check_model]]5. Advanced Degree1. Yes(Intercept)131.1513.0210.080.00105.55156.75[[check_model]]5. Advanced Degree1. Yesage0.540.291.880.06-0.031.10[[check_model]]3. Some College2. No(Intercept)44.848.745.130.0027.5962.08[[check_model]]3. Some College2. Noage1.340.226.040.000.901.77[[check_model]]1. &lt; HS Grad1. Yes(Intercept)78.746.9111.390.0065.0692.43[[check_model]]1. &lt; HS Grad1. Yesage0.330.152.220.030.040.62[[check_model]]\n\n\n\n\n\n\n\nCode\nnested_models |&gt;  \n  unnest(quality) |&gt;  \n  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) |&gt; \n  arrange(adj.r.squared) |&gt; \n  mutate_if(is.numeric, ~ round(., 2)) |&gt;  \n  regulartable() |&gt;  \n  autofit()\n\n\n\neducationhealth_insr.squaredadj.r.squaredsigmastatisticp.valuelogLikAICBICnobsperformance4. College Grad2. No0.010.0035.771.310.25-778.391,562.771,571.92156[[check_model]]1. &lt; HS Grad2. No0.010.0020.141.450.23-635.691,277.381,286.29144[[check_model]]5. Advanced Degree1. Yes0.010.0153.333.530.06-1,892.833,791.663,803.24351[[check_model]]2. HS Grad1. Yes0.010.0127.567.510.01-2,897.115,800.225,813.47612[[check_model]]5. Advanced Degree2. No0.030.0151.511.890.17-401.04808.08815.0475[[check_model]]4. College Grad1. Yes0.020.0240.349.120.00-2,705.505,417.005,429.81529[[check_model]]1. &lt; HS Grad1. Yes0.040.0318.904.920.03-539.421,084.831,093.30124[[check_model]]2. HS Grad2. No0.050.0425.7817.000.00-1,674.983,355.963,367.61359[[check_model]]3. Some College1. Yes0.060.0626.9931.020.00-2,200.624,407.244,419.68467[[check_model]]3. Some College2. No0.170.1636.0436.510.00-914.661,835.311,844.94183[[check_model]]\n\n\n\n\nCode\nunnested_preds &lt;- \n  nested_models |&gt; \n  unnest(preds)\n\n\n\n\nCode\nggplot(df, aes(x = age, y = wage, group = health_ins)) +\n   geom_point(aes(color = health_ins), alpha = 0.2, shape = 1) +\n   geom_smooth(method = \"lm\", size = 2) +\n   facet_grid(. ~ education, scales = \"free\") +\n   geom_line(data = unnested_preds, aes(y = .fitted, age, color = health_ins)) \n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead."
  }
]